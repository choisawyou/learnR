2019/11/26 - 1회차
R은 패키지 성격 ^
복습 위주
컴퓨터 구조/원리
GIT                                                

컴퓨터 시스템
1.하드웨어
1)CPU_ALU,Register,CU로 구성
  > ALU(연산{+-x >=<}장치 ), Register → CU(제어장치)

*CPU명령 Cycle*
명령 Fetch (Memory에서data읽기) > 명령 Decode(명령해석) > 명령 Excute

2)Memory(RAM/ROM)_code&data로 이루어짐
RAM 전원을 끄면 다 사라짐
ROM 전원에 상관없이 저장_RAM대비 상대적으로 느린속도
3)I/O(in/out put) Device
eg) 스마트폰의 터치,스피커,마이크,볼륨버튼,
     냉장고 상태 표시 스크린, TV 화면 등

연결상태 및 과정
* CPU↔Memory→I/O Device _ CPU와 I/O DEVICE 는 직접 x
eg) 2+5 에서 '2,5'는 data / '+' 는 code


2.소프트웨어
1)시스템 S/W_하드웨어 제어 관점
2)어플리케이션 S/W_사용자(End-user)관점
   >요새는 UI 보다 UX의 중요성 ^


*1bit (0/off or 1/on) X 8 = 8bit => 1 byte (컴퓨터 최소 표현단위)
1byte로 표현 가능 종류는 256가지(2의 8승)
컴퓨터는 0과 1만 알기 때문에 code표(protocol_약속) 필요
대표적인 코드표는 ASCII_8bit / UNIcode_2byte / UTF 8_글자 표현방식(한글 깨질 확률↓)

Operating system (운영체제)
 >H/W(cpu,memory,i/o device) 제어

*메모리 접근 절차*★
1.메모리 주소 지정(숫자 부여)_Address Bus
2.동작 결정(read or write)_Control Bus
3.Data/Code를 결정된 동작으로 수행_Data Bus

CPU 와 Memory를 연결하는 선을 BUS라고 함
1.Address Bus
2.Data Bus
3.Control Bus
높은 bit를 쓸 수록 속도가 ^ ( 연결하는 선이 많아지므로!)
32bit CPU는 4GB가 한계

1차 Memory(main Memory)_보관,실행 모두 가능
2차 Memory(보조 Memory) _only 보관기능, 소멸x
>USB,HDD,SDD
File: 보조메모리에 저장하는 단위
2차메모리를 1차메모리로 가져와야함
반드시 보조기억장치가 있어야 컴퓨터가 작동 

*Version Control System (VCS_버전관리시스템)*
Server(service 제공자)
Client(service 요청자)

1.중앙집중식(SVN,CVS)
Client가 작업한것을 Server에 저장하고,필요할 때 불러다 씀
장점: 서버만 잘 구성하면 됨
단점:서버에 문제가 생기면 클라이언트는 아무것도 못함
2.분산식(Git_GitHub{협업서버역할})
Client 각자 VCS 운영, 필요할 때 Client끼리
연결하거나 한군데로만 연결
장점:필요할 때 연결하기만 하면되고 내가 했던 기록이 남음
단점:각자 VCS를 운영해야하는부분 


확장자 => 드라이브>좌측상단 파일> 폴더및검색옵셥>보기탭>확장자,드라이브체크표시해제
exe/msi은 실행가능 file
이외에는 더블클릭시 실행 불가

cf) C:\Program Files\Git
[C드라이브/루트/프로그램파일s/밑에,아래/깃]
Users에는 프로그램 설치 x 

git : https://git-scm.com/

Git Editor_ 
Vim 은 리눅스용 (단축키알아야함)_설치x
Use Visual Studio Code as Git's default editor 설치하기
>명령프롬프트 cmd 실행 후
>git --version

CLI(Command Line Interface) 명령을 입력하는 방식
cmd가 환경구성

글씨체 링크
https://sourcefoundry.org/hack/
https://github.com/naver/d2codingfont

c: 드라이브를 c로 변경
cd\ => 디렉터리 변경
dir /w=> 현재디렉터리를 간략하게보여줘 명령
명령/옵션

git 이용한 version 관리 절차
1. 관리할 디렉터리에서 
git init  : 초기화

2.버전 관리할 대상 추가
git add [file명] : 추가

git status : 상태확인

3. 커밋 수행
git commit -m "설명"

https://github.com/
https://desktop.github.com/

*Blockchain_Big data*

빅데이터 참고자료
- https://ko.wikipedia.org/wiki/빅_데이터 
- https://m.blog.naver.com 데이터마이닝 포스트 
- 따라하며 배우는 데이터 과학(권재명 지음) - Jpub

 *Program language 유형*

1.Compile방식
장점: 실행속도가 빠름
단점: 변경할 경우에는 통째로 변경해야함.환경구축 복잡
2.Interpreter 방식(Script형태)
대표eg.Web , R
장점:간편하다
단점:실행속도가 느리다

1단계 :Source Code(Source File)
 >Editor 이용
2단계 : Object Code
>Complier 이용 
3단계 : Execute Code
>Execute file
4단계 : 결과

Compile 단계별 사용 프로그램
1-2 = Complier
2-3 = Linker
3-결과 = Loader

단계별 생성 파일
1 = Source file
2 = Object file_실행 불가능한 binary file
3 = Execute file _실행 가능한 binary file

단계별 발생 Error: 
1-2 = Syntax error
2-3 = Link error
결과 = Runtime error 

*R은*
1. Interpreter 방식
2. Open source
-강제 소스 오픈 GPL,LGPL/
-APL,MPL,BSD
3.시장모델_ 누구든 참여가능

2019/11/27 - 2회차
42pg/114pg/115pg ~122pg

hw: 1~1000까지 3의 배수와 5의 배수를 한줄에
10개씩 출력하고 마지막에 개수를 출력

*개발언어 교육과정
1.개발환경_R(Interpreter),Rstudio(IDE_통합개발환경)
2.★자료형(변수)★
3.연산자
4.제어문
-Library(알고리즘{일처리순서}+자료구조)
1)제공되는 Library(사용방법)
2)사용자 정의 Library(작성)*
>함수
>Class
5.입/출력

*알고리즘(메모리 내용을 어떻게 바꿀것인가) 필요조건
1.유한성_모든 프로그램은 '끝'나야한다
2.0개 이상의 입력(Memory기록)_입력이 0일 수 있다
3.1개 이상의 출력(Memory내용출력)_출력은 반드시 有
4.유효성_유효한 알고리즘 
5.효과성

*Data type(자료형)
R_원시 자료형(Scalar)_가장 낮은 타입의 형태
 >컴퓨터 시스템에서 사용하는 Data type
숫자/문자 구분 기준: 산술 연산 가능 유무
eg.휴대폰 번호는 숫자이지만 산술연산X
1.숫자
-정수
-실수_나눠서 나머지가  0이 아님
2.문자
3.논리형 (True or False)

*git:version 관리 tool
1.local영역version 관리(나혼자)
>git
2.global영역 version관리(타인과 공유)
>git/github

*Repository(git의 저장소)
https://github.com/choisawyou/WorkR.git
긴명령 or drag해서 repository에 파일 올릴 수 있다 
파일 크기제한 하나당 25MB이하

*git 만들기(cmd로)
1.git 초기화(1회성)
>git init /C:\workR>git init
2.file 추가
>git add [file명] file명은 = .으로 대체가능
3.commit
>git commit -m" create to file [file명]"

cmd에서 처음 1번만하기 _이메일은 깃허브 상 이메일, 아이디
C:\workR>git config --global user.email"choisawyou@gmail.com"
C:\workR>git config --global user.name "choisawayou"

C:\workR>git status _ 상태확인
C:\workR>git add first.R
C:\workR>git commit -m "create to file [first.R]"
C:\workR>git log_사용이력

github desktop  

R에서 왼쪽 알트 + [-] =<-
C:\workR>git add first.R

C:\workR>git commit -m "add to line [ number <- 10 ]"

C:\workR>git remote add origin https://github.com/choisawyou/WorkR.git
>  로컬과깃허브의 저장소를 연결
C:\workR>git push -u origin master
>푸시해서 올리기


*변수 : 값을 저장/변경하는 기억장소
 ★★★변수의 기능★ ★★
1.값 쓰기 _L value_값의 변환
2.값 읽기_R value_값의 변환 X
치환연산자 기준
왼쪽 : L value
오른쪽 : R value
eg.
{number<-10}
변수이름:number
치환연산자: <- or =
값:10

*변수
1.속성(attribute)_기억장소 모양
1.1 자료형(data type)_숫자 , 문자 등★
1.2 기억장소크기_ R이 알아서 만들어줌(통상 정수 4byte)
1.3 값 저장방식_R이 알아서
eg)32bit 중 첫 bit는 부호 (+:0,-:1)
1.4  값의 범위_R이 알아서
>overflow,underflow : 값의 범위 초과 및 미달의 에러
2.연산(기능,동작)_기억장소 이용/변경 동작
2.1 읽기 기능
-R value
-출력명령
2.2 쓰기 기능
-L value
-입력명령
2.3 산술/관계/논리 연산(operator)_기호형태

-산술(사칙연산)
>결과값 : 숫자
-관계(대소비교)
>결과값 : 논리형
-논리(또는/그리고)
>결과값 : 논리형


변수 생성 방법
-정적 자료형으로 생성_변경x
> complie형 언어(c,c++,java)
-동적 자료형으로 생성_필요에의해 변경 가능
>interpreter(script)형 언어(R,python,js)

*program
1.기억장소 확보
2.기억장소 내용을 알고리즘에 따라
읽기/쓰기하여 결과 도출 


*Rstudio
numberValue <- 1   #camel 표기법(소+대문자)
str_value <- "R Language"   #snake 표기법(언더바)
booleanvalue <- TRUE #소문자표기법
변수명의 시작은 숫자로 시작 불가 & 소문자로시작
내가 원하는 표기법 선택
R은 대소문자 구별.

print( numberValue)
print( str_value)
print( booleanvalue)

cat( "Numeric number : ", numberValue, "\n")
cat( "String : ", str_value,"\n" )
cat( "Blooean value : ",booleanvalue, "\n")
Escape chatacter
\n :줄바꿈
\+ :tab 간격

numberValue <- scan()
cat( "Numeric number :", numberValue, "\n")

print/cat 읽는함수_출력명령
scan 쓰기함수_입력명령

number1 <- 10
number2 <- 20
resultAdd <- number1 + number2
resultSub <- number1 - number2
resultMul <- number1 * number2
resultDiv <- number1 / number2
resultRem <- number2%% number1
resultSec <- number2 ^ 5
> print( resultAdd )
[1] 30
> print( resultSub)
[1] -10
> print( resultMul)
[1] 200
> print( resultDiv)
[1] 0.5
> print( resultRem)
[1] 0
> print( resultSec)
[1] 3200000

number1 <- 0
number1 <- number1 + 10   => 누적 ( 동일 변수가 L/R  value에 존재_기존내용 보존)
number1
상위경우에는 [연산 우선순위]에 따라 Rvalue 먼저 계산
동순위의 연산자(곱셈 나눗셈 등)의 경우

cf) 
number1 <- number1 + 10 => 누적 ( 동일 변수가 L/R  value에 존재_기존내용 보존)
number1 <- number2 + 10 는 치환  ( 기존 내용은 지워짐 )
누적할 때에는 필수로 초기값 설정

*관계연산자*
(대소비교)
number1 <- 10.5
number2 <- 10

> number1 <- 10.5
> number2 <- 10
> print ( number1 > number2 )
[1] TRUE
> print ( number1 >= number2 )
[1] TRUE
> print ( number1 < number2 )
[1] FALSE
> print ( number1 <= number2 )
[1] FALSE
> print ( number1 == number2 )
[1] FALSE
> print ( number1 != number2 ) = > 같지않다
[1] TRUE

(논리연산)
print ( number1 > 10 & number2 >10 )     #AND
print ( number1 > 10 | number2 > 10 )    #OR
print ( !( number1 > 10 ) )              #NOT

number <- "100"
str <- "R Language"
result = number + str
print ( result )
>>Error in number + str : 이항연산자에 수치가 아닌 인수입니다


*제어구조 : program 실행 흐름을 제어
-순차구조: 명령어 차례대로 나열(명령 흐름은 위에서 아래 방향으로 흐른다)
-선택구조: if ~ else 문 사용=> 괄호必안에 조건식 必
-반복구조: for,while

#
#제어구조 - 선택구조
#
1.양자택일 구조 (if~else)
job.type <- 'A'

if ( job.type == 'b') {
  bonus <- 200              #참일때
  } else {                        #조건이 거짓일때
   bonus <- 100 
}
cat ( "job type :", job.type, "\t\tbonus : ", bonus )
job type : A 		bonus :  100

2. 단순구조(if)

job.type <- 'B'
if  ( job.type == 'A') {
  bonus <- 200
}
cat ( "job type : ", job.type, "\t\tbonus :", bonus )
job type :  B 		bonus : 100

3.다중선택구조 (if ~ else if~ else~)_조건문의 순서가 중요 !
score <- 85
if (score >= 90 ) {
  grade = 'A' 
}  else if ( score >= 80 ) {
  grade <- 'B'
} else if ( score >= 70 ){
grade <- 'C'
} else if ( score >= 60 ) {
   grade <- 'D'
} else {
  grade <- 'F'
}
cat ( "score : ", score, "\t\tgrade :" , grade)
score :  85 		grade : B

연습문제_짝홀수 판단

number <- 15

#remainder <- number %% 2
#if ( remainder == 0)

if ( number %% 2 == 0 ) {
  result <- "짝수"
} else {
  result <- "홀수"
  } 
cat ( "Number : ", number, "는 " , result ,"이다" )
Number :  15 는  홀수 이다


==================================
 a <- 10
 b <- 20
 
 if ( a > 5 & b > 5 ) {
   cat ( a, " > 5 and ", b, "> 5 " )
} else {
 cat( a, " <= 5 or " , b, " <= 5 " )
   }

==================================
a <- 10
b <- 20
  
 if ( a > b ) {
   c <- a
 } else {
   c <- b
 }
 cat("a = ", a, "\tb = ", b, "\tc = ", c )
  
 c <- ifelse( a > b, a, b )
 cat( "a = ", a, "\tb = ", b, "\tc = ", c )
 
========================================

Package ; 함수 library 집합

 
 #제일 큰 수를 max에 저장 후 max를 출력
 
 a <- 10
 b <- 5
 c <- 8
max <- a

if ( b > max ) {
  max = b
} 

if ( c > max ) {
  max = c 
}

cat( " a = ", a, " b = ", b, " c = ", c, " max = ", max )



#반복구조
#for 문_범위가 명확할 때 사용

for ( i in 1:10 ) {
  print( i )
}

[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10

for ( 반복 1회 째의 내용이 저장  in  반복범위 시작 : 반복범위 끝 )

multiple = 2
for ( i in 2:9 ) {
  cat( multiple, 'X', i, ' = ', multiple *i, '\n' )
}
2 X 2  =  4 
2 X 3  =  6 
2 X 4  =  8 
2 X 5  =  10 
2 X 6  =  12 
2 X 7  =  14 
2 X 8  =  16 
2 X 9  =  18 

#while문_ 반복 제어변수(i) 반드시 설정__ 범위가 애매할때 

i <- 1
while ( i <= 10 ) {
  print( i )
  i <- i + 1
}

#1-100까지 한줄에 10개씩 출력 

#1 #Reset
for (s in 1:100) {
  cat( s,' ' )
  if ( s %% 10 == 0 ) {
    print( '\n' )
  }   
}

#2 #초기화
lineCount <- 1
for ( i in 1:100 ){
  cat(i, ' ')
  lineCount <- lineCount + 1
  if ( lineCount > 10 ) {
    print( '\n')
    lineCount <-1
  }
}  


Keyword = Reserved word => 예약어
User Define word => 사용자 정의어

{} ←code block
\t← tab 간격만큼 띄어쓰기


hw: 1~1000까지 3의 배수와 5의 배수를 한줄에
10개씩 출력하고 마지막에 개수를 출력


linecount<-1
count<-1

for ( i in 1:1000){
   if( i %% 3 == 0 | i %% 5 == 0 )
        cat(i , " ")
   count <- count + 1 
   linecount <- linecount +1
    if ( linecount > 21 ) {
      print("\n")
        linecount <- 1 
    }
}

cat ("총 갯수 : ", count , "개")


2019/11/28- 3회차
122pg ~128pg,133pg, 59~64pg(벡터) , 72~76 pg (list )
44~45pg( as/is 함수)

지난 hw: 1~1000까지 3의 배수와 5의 배수를 한줄에
10개씩 출력하고 마지막에 개수를 출력

*프로그램 작성 절차
1.문제 정의/이해
2.기억장소 결정
3.알고리즘 결정 =>제어구조 이용
=>pseudo code
1. 1 ~1000까지 반복
1.1 3의 배수인지 판별
1.2  5의 배수인지 판별
1.3 3의배수이거나 5의 배수이면
갯수를 세고, 그 수를 출력한다.
2.갯수를 출력한다.
====================================

#1~1000까지 3의 배수와 5의 배수를 한줄에
#10개씩 출력하고 마지막에 개수를 출력

i <-1
count <- 0
linecount <- 1
multiple3 <- NULL
multiple5 <- NULL
while( i <= 1000 ) {
  multiple3 <- i %% 3
  multiple5 <- i %% 5
  if( multiple3 == 0 | multiple5 == 0 ) {
    count <- count + 1
    cat ( i , " ")
    linecount <- linecount + 1
    if (linecount > 10 ) {
      linecount <- 1
      print( "\n" )
    }
  }
  i <- i + 1              #while 문은 이게 없으면 무한반복
}
print( "\n" )

cat ( "1 ~ 1000 사이의 3의 배수와 5의 배수의 개수 : " , count, "\n")
====================================================

#
#break/next
#
sum <- 0
for ( i in 1:10) {
  sum <- sum +  i
  if ( i >= 5) {
    break          # 반복을 빠져나가라
      }
}
sum #15

#next

sum<-0
for ( i in 1:10){
  if ( i %% 2 == 0) {
    next     #다시 반복 제어문으로 올라가기
  }
  sum <- sum + i
}
sum #25

#2의배수를 제외하고 합계
=============================================================

*함수(Function)_단위(하나의) 기능을 수행하는 code 집합 (Block)
>반복적인 기능을 별도로 작성하기 위해서 함수 작성
1.내장함수 ( library 함수)_R에서 제공하는 함수_기본제공
2.사용자 정의 함수 
-제3자 함수_필요시 설치해서 사용
-사용자 정의 함수

cf)package:함수를 포함한 파일

#
#산술 내장 함수

log ( 10 ) + 5        #로그함수 _ 로그함수 return값에 +5
log ( 10, base = 2)   
sqrt( 25)                   #제곱급(Square Root)
max(5,3,2)              #가장 큰 수(
min(5,3, 2)              #가장 작은 수
abs( -10)                #절대값(absolute value)
factorial(5)             #팩토리얼
sin ( pi / 2 )             #삼각함수


함수호출 => 'log(10)' => return 값 
-log:함수명
-인수 list : 10_ 항상 괄호 ! 0개이상
-return 값 : 함수 동작 후 되돌려 주는 값 (항상 1개 or 0개)
1.함수 정의_내장함수는 이미 정의 완료된 상태
2.함수 호출



*사용자 정의 함수 정의
함수명 <- function ( [인수 list] ) {
함수내용 code 작성
return ( 되돌릴값)
}
리턴값은 항상 한개
*함수 유형
1. 인수없고, return 없는 경우
2. 인수있고, return 없는 경우
3. 인수없고, return  있는경우
4. 인수있고, return  있는 경우

=====================================
#
#사용자 정의 함수

mymax <- function (x,y){            #함수정의
  num.max <- x
  if ( y > num.max ) {
    num.max <- y
  }
  return ( num.max )
}

mymax( 10,15)                        #함수 호출
[1] 15

a <- 10
b <- 5
c <- 8
max <- mymax ( a,b)
max <- mymax ( max,c)
max
[1] 10
=======================================


#사용자 정의 함수 매개변수 초기값 설정

mydiv <- function ( x, y = 2){              # 인수(y)의 default(2) 값 설정 , 초기값은 항상 오른쪽만 설정가능
  result <- x/y
  
  return ( result)
}

mydiv ( x = 10 , y = 3 )     #[1] 3.333333
mydiv ( 10,3 )                   #[1] 3.333333
mydiv ( 10 )                       #[1] 5  _ y 값이 안들어왔을 때 default값 사용

===========================================

#외부 파일에 있는 함수 호출
#함수 정의한 스크립트 생성 후 실행하기 

setwd( "C:/workR")           #경로 지정
source ( "mylib.R")          #lib파일(함수정의 script)지정_사용할파일

#함수 호출
my_max(10,5)
my_div(10,2)

============================================

Scalar(원시값) : 하나의 값 ( 숫자 or 문자 or 논리 )

scalar를 메모리에담기위해  변수 생성
eg)a <- 10
a는 10이라는 scalar를 담는 변수

*Vector ( 1차원 배열, 열의 집합,동일 자료형 집합, scalar형 기억장소 집합 )

eg)
-1층 아파트  -> vector명
101호 102호 103호 . . ._> index
-A -> vector 명
 1,2,3,4,5 -> index

R의 index는 항상 1부터 시작 
python 의 index는 0부터 시작



#
#vector
#

#scalar 변수 사용
a <-10
b <- 5
c<- 8
max <- a
if ( b> max ) { max <- b }
if ( c > max ) { max <- c}
max  [1] 10

#vector 사용

v <- c (10, 5, 8)
max <- v [ 1 ]
for ( i in 2:length (v) ) {
  if ( v [ i ] > max  ) {
    max <- v [ i]
      }
}

max  [1] 10

============================

#vector 생성 _ c 함수
 
x <- c ( 1,2,3 )               #[1] 1 2 3
y <- c ( " a ", " b ", " c " ) #[1] " a " " b " " c "
z <- c ( TRUE, TRUE , FALSE , TRUE ) #[1]  TRUE  TRUE FALSE  TRUE
x;y;z
      
#class는 자료의 속성을 알려줌

class ( x )  #[1] "numeric"
class ( y )  #[1] "character"
class ( z )  #[1] "logical"

w <- c( 1, 2, 3, 'a','b','c')
w
class (w)       #[1] "character" #vector는 무조건 동일 자료형 !

==================================
#vector 생성 방법  " : "

v1 <- 50:90
v1
v2 <-  c(1, 2, 3, 50:90)
v2

class ( v1 ) 
class ( v2 )

#vector 생성 방법seq (시작값, 끝값, 간격)

  v3 <- seq (1, 101, 3 )     
  v3
  v4 <- seq ( 0.1,1.0,0.1)
  v4
  
#vector 생성방법rep (1 , times = 반복횟수)  
  
  v5 <- rep ( 1, times = 5 )
  v5
  v6 <- rep ( 1:5, times =3 )
  v6
  v7 <- rep ( c ( 1 ,5 ,9), times =3 ) 
  v7
      



  #벡터 원소값에 이름지정
  #names 는 이름을 지정할 때 사용
  # 이름 지정할 갯수와 벡터함수내 갯수 일치해야함
  score <-  c ( 90, 85, 70 )  
  names ( score )  #결과 : NULL
  names ( score ) <- c ( "Hong", "Kim", "Lee" )  
  names ( score ) #결과 : "Hong" "Kim"  "Lee"
  score #결과 : Hong  Kim  Lee 
  
  
  
  #벡터 원소 접근
  score [ 1 ]
  score [ 2 ]
  score [ 3 ]
  score ["Hong"]
  score [ "Kim"]
  score [ "Lee"]
  
  d <- c (1,4,3,7,8)
  d[1]  #1
  d[2]  #4
  d[3]  #3
  d[4]  #7
  d[5]  #8
  d[6]  NA 
   *NA _ 결측치 (missing value)_읽을 수 없다
cf) NULL : 아무것도 없다
      NAN(not a number) : 계산할 수 없다. 
      inf(infinity) : 무한대

=========================================================
  for ( i in 1:length ( score )){      # score 함수 1부터 마지막까지를 나열
    print ( score [i])
  }
  
  score_names <- c ( "Hong", "Kim","Lee")
  for ( i in 1 :length ( score)){
    print (score [ score_names [i]])
  }


#벡터에서 여러 개의 값을 한번에 추출 _ ★실제에서 많이 쓰는 방법 ★
  
  d <- c( 1,4,3,7,8 )
  d[ c ( 1,3,5 ) ]  #1번 3번 5번 인덱스 값 1 3 8
  d[1:3]  # 1~3까지의 인덱스 값 1 4 3
  d[ seq(1,5,2)]  # 1번 3번 5번 인덱스 값 1 3 8
  d[-2]   #"-"는 제외의 의미  1 3 7 8
  d[-c(3:5)]  # 3번4번5번 제외 1 4
    
GNP <- c( 2090, 2450 , 960 )
GNP

names ( GNP) <- c ( "Korea", "Japan" , "Nepal" )
GNP

GNP[1]
GNP["Korea"]
GNP[ c ( "Korea" , "Nepal" ) ]
 

#result
 > GNP[1]
Korea 
 2090 
> GNP["Korea"]
Korea 
 2090 
> GNP[ c ( "Korea" , "Nepal" ) ]
Korea Nepal 
 2090   960  


#백터 요소값 변경 ★

v1 <- c(1, 5, 7, 8, 9 )   
v1 #1 5 7 8 9

v1[ 2 ]  <- 3
v1 #1 3 7 8 9

v1[ c (1,5) ] <- c(10,20)
v1 # 10  3  7  8 20


#벡터간 연산_동일 인덱스에 있는 값끼리 연산 
# 두 벡터간 요소의 갯수가 같아야함

x <- c (1,2,3)
y <- c (4,5,6)
> x + y
[1] 5 7 9
> x * y
[1]  4 10 18
> z <- x+y
> z
[1] 5 7 9




#벡터에 적용가능한 함수

d <- c(1,2,3,4,5,6,7,8,9,10)
sum ( d )  # 합계
sum( 2 * d )
length ( d)            #벡터의 요소 개수(길이)
mean( d [1:5])         #평균
mean( d )
median(d[1:5])                 #중앙값
median ( d )
max( d )                        #최대값
min( d )                        #최소값
sort( d )                       #정렬
sort( d, decreasing = FALSE)
sort( d, decreasing = TRUE )
range(d)                       #값의 범위 (최소값~ 최대값)
var( d )                      #분산
sd ( d )                      #표준편차

v <- sum( d ) / length( d )  #평균 구하는 방법
v

 #벡터에 논리 연산 적용★★★

 d>= 5
 [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

 d[ d>5] 
[1]  6  7  8  9 10

 sum ( d > 5)   #갯수
[1] 5

 sum( d [ d>5]) #합계
[1] 40
 d == 5
 [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
 
# cond <- d > 5 & d < 8 
#cond
 [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE

 d[cond]
[1] 6 7

 all ( d > 5 ) #false _전체가 5보다 크냐 
 any ( d > 5 ) #true_하나라도 5보다 크냐


head ( d )   # 1 2 3 4 5 6  #default 값은 기본 6개 
 tail ( d )   #5  6  7  8  9 10
 head (d,3)   #1 2 3  # 갯수 지정
 tail (d,2)   #9 10   # 갯수 지정 
 
 x <- c ( 1,2,3)
 y <- c (4,5,6)
 z <- c (3,1,2)

 w <- c(x,y)   # 벡터x와 벡터y 결합 
 W
 union(x,y)              #합집합
 intersect(x,y)        #교집합
 setdiff(x,y)             #차집합
 setequal(x,y)         #x,y에 동일한 요소가 있는지 확인 #FALSE

 
자료구조 
Vector : 동일 자료형 기억장소 집합  
List : 다른 datatype의 자료를 저장하는 구조 
 -Key(변수) : value 형식으로 저장
cf)Factor 형 :범위형 type ( 범위 지정 eg. 남/여 , 초/중/고급 , 예/아니오)



 #LiST_ Key(변수명)와 index로 접근 모두 가능
 
 ds <- c(90,85,70,84) #얘는 벡터
 my.info <- list( name = 'Hong', age = 30 , status = TRUE, Score = ds)  
 
 #name,age,status,score 가 KEY
 # 각 값이 value
 my.info         
 my.info[ 1]              # 대괄호 1개는 인덱스 전체 
 my.info [[1]]            #대괄호 2개는 value 값 도출
 my.info$name             # Key이름 앞 $ 붙이기
 my.info[[4]]             # 벡터 내용 전체
 my.info[[4]] [1]         # 벡터 1번째 index

#Factor형(범주형)
bt <- c ( 'A', 'B', 'B','O','AB' ,'A') #bt는 벡터
bt.new <- factor( bt )       #factor 형 벡터
bt
bt.new           # Levels: A AB B O _ Levels 는 가질 수 있는 값의 범위 
bt [5]                #"AB"
bt.new [5]          #AB
levels ( bt.new )          #Level의 범위 값이 보고싶을 때 사용하는 함수 
as.integer ( bt.new )           #정수로 변환해라 _as는 변환함수 _Level에 맞춰 숫자 변환
bt.new [7] <-                 "B" 
bt.new [8] <- "c"           #C는 Levels에 포함되지않기 때문에 에러 but 값이 생성됨
bt.new
         
  2019/11/29- 4회차
진도 : matrix 64~69pg, Dataframe 77pg, CSV 98pg ,Write.csv109pg

11월 마지막주 진도 내용 
42~45pg/59pg~69pg/72pg~84pg/113pg~135pg

Lvalue <- Rvalue
변경되어야 하는 값이 왼쪽!

*Local 버전관리
-git_init (한번만)
-git_add_file명
-git_commit_-m_"설명"

*local 파일을 github에 올릴 때
-git_push 
-git_remote
-github desktop _>commit / push

*github에서 가져올 때 쓰는 명령
-git_clone ( 초기에 가져올 때 1회만)
-git_pull  ( 이후에 자료 내려받을 때)
-github desktop _> file-clone repository( 초기에 가져올 때 1회만)
-github desktop _>repository_pull

*share files with others_github 

setting -> collaborators-> Add collaborator

=================================

*scalar(값) -> 일반 변수 
data type(숫자,문자,논리,null,na,nan,factor(범주형))

NA _ 결측치 (missing value)_읽을 수 없다
NULL : 아무것도 없다
NAN(not a number) : 계산할 수 없다. 
inf(infinity) : 무한대

#List 함수
#함수 반환값(return 값)이 여러 개일 때 의 처리

myfunc <- function ( x, y){
  val.sum <- x + y 
  val.mul <- x * y
  
  return ( list ( sum = val.sum , mul = val.mul ) )
  }

result <-  myfunc ( 5, 8)
s <- result$sum
m <- result$mul
cat ( '5 + 8 = ', s,'\n')
cat ( '5 * 8 = ', m, '\n')

====================================
*1차원 배열(동일자료형 집합) -> vector
*1차원 배열(다른자료형 집합) ->list
*2차원 배열(행/열)의 집합_동일자료형) -> Matrix
 eg) 10명의 키,몸무게,나이(숫자형)를 조사할경우
행=관측치 라고 부르기도함
열=변수,특성 라고 부르기도함

=> 이상황에서 이름(문자)를 추가할 경우 -> Data Frame

Matrix : 2차원 구조 (배열), 동일 자료형 행/열 집합
4x3 Matrix
행x열
열(변수(variable), 특성(feature))
행(관측치observation)
> 데이터분석을 할 때에는 관측치보다 변수가 더 중요하다
행과 열이 만나는 지점은 cell

=======================================
#Matrix 생성
#cloumn -> 행(관측치)_가로 row->열(변수)_세로
#R은 열 우선방식이 default
#matrix가 다 채워질 수 있도록 설정한 열|행의 배수로 숫자 설정

z <- matrix( 1:20, nrow = 4) # 열 우선 방식 
z

z <- matrix( 1:20, ncol = 4 )
z

z <- matrix( 1:20, nrow = 4, ncol = 5)
z

#byrow 행우선  방식
z <-  matrix( 1:20, nrow = 4 , ncol = 5 , byrow = T ) 
z

x <- 1:4
x
y <- 5:8
y
z <- matrix(1:20,nrow = 4,ncol = 5 )
z
m1 <- cbind(x,y)  #cbind 열로 결합
m1
m2 <- rbind(x,y)  #rbind 행으로 결합
m2
m3 <- rbind(m2,x)
m3
m4 <- cbind(z,x)
m4
=======================================          
#Matrix에서 cell 값 추출
z <- matrix(1:20,nrow = 4,ncol = 5 )
z

z[2 , 3] #2행3열
z[1 , 4] #1행4열
z[2,]    #2행 
z[,4]    #4열 

z[2 , 1:3]       #2행의 1열부터3열
z[1, c(1,2,4)]   #1행의 1열2열4열
z[1:2,] 
z[ ,c (1,4)]     #1열과 4열전체

#Matrix에서 행/열 이름 지정
score <- matrix(c(90,85,69,78,85,96,49,95,90,80,70,70),
                nrow = 4 , ncol = 3)
score
rownames(score) <- c( "Hong" , "Kim", "Lee", "Yoo") #관측치
colnames(score) <- c("English", "Math", "Science") #변수
score

score[ 'Hong', 'Math']
score[ 'Kim',c('Math', 'Science')]
score[ 'Lee']
score[ ,'English']
rownames( score )
colnames (score)
colnames (score) [2]

=======================================

#Data Frame 생성_matrix에 비해 변수가 더 중요 ! 

city <-  c( "Seoul", "Tokyo" , "Washington")        #변수이름이 별도의 설정없이 들어가 있다.
rank <-  c(1,3,2)
city.info <-  data.frame ( city, rank )      #함수이름은 data.frame
city.info
                  
name <- c("Hong","Kim", "Lee")
age <-  c(22,20,25)
gender = factor( c ("M","F","M"))
blood.type =factor(c ( "A", "O" , "B"))
person.info <- data.frame( name, age, gender, blood.type)
person.info

person2.info <- data.frame( name = c( "Hong","Kim","Lee"),age = c( 22, 20, 25),
                             gender = factor(c("M","F",'M')),
                                             blood.type = factor( c ( "A","O","B")))
  person2.info
  =======================================
#Data Frame : 2차원 구조, 동일/다른 자료형의 행/열 집합
(변수(열)는 동일 자료형, 관측치는 다른 자료형일 수 있다.)

city.info[1,1]
city.info[1,]
city.info[,1]
city.info[ city.info$city, ]
city.info[ , "rank"]

person.info$name
person.info[ person.info$name == "Hong", ]
person.info[ person.info$name == "Hong", c( "name", "age")]

#R제공 기본 데이터 셋 -> data()

iris

iris[ , c(1:2)]
iris[ , c(1, 3, 5)]
iris[ , c( "Sepal.Length", "Species")]
iris[ 1:5]
iris[ 1:5, c (1,3)]
=======================================
#Matrix 와 Data Frame 에서 사용하는 함수

name <- c("Hong","Kim", "Lee")
age <-  c(22,20,25)
gender = factor( c ("M","F","M"))
blood.type =factor(c ( "A", "O" , "B"))
person.info <- data.frame( name, age, gender, blood.type)
person.info 

=======================================
dim( person.info)    #★관측치,변수 갯수 
dim ( iris) 
nrow( person.info)
nrow(m3)
ncol(person.info)
ncol(m3)
head( iris)                        #앞부분 일부
tail( iris)                           #뒷부분 일부
str( iris)                            #★데이터의 형태,관측치 수obs, 변수의수 variables :
str( city.info )                  #★변수이름($blah)과 자료형(num) 
str( person.info )            #★factor형으로 자동 변경이 되는 경우가 있음 
iris[ , 5]
unique(   iris[,5])            #중복된 데이터 하나씩 뽑아서 factor로 나열
table(iris[,"Species"])              #★종류별 카운트_Factor type일 때 가능 
table( person.info[ , "blood.type"]) 
table( person.info[ , "gender"] )
 =======================================   
#Matrix/Data Frame 사용 함수
#행별/ 열별 합계와 평균계산

colSums( iris[ , -5] )           #변수의 합계 / 5번째 column(factor type 제외 )
apply( iris[ , 1:4 ] , 2 , sum)  # apply(범위, 1: row방향/2:column방향,내가하려는 동작)

colMeans( iris[ , -5 ] ) 
apply( iris[ , 1:4 ] , 2 , mean)

rowSums( iris[ ,-5 ] )  
apply( iris[ , -5 ] , 1 , sum)

rowMeans( iris[ , -5 ] )  
apply( iris[ , -5 ] , 1 , mean)

apply( iris[ , -5 ] , 2 , median) #중앙값



#행/열 방향 전환
z <- matrix( 1:20 , nrow = 4 , ncol = 5)
z
t( z )

#조건에 맞는 행과 열의 값 추출 (Data Frame만 가능)
IR.1 <- subset( iris , Species == "setosa")  #subset 조건에 맞는 관측치 출력 
IR.1

IR.2 <- subset( iris, Sepal.Length > 5.0 & Sepal.Width > 4.0)
IR.2
IR.2[ , c(2,4)]


#Matrix / Data Frame 산술연산

a <-  matrix ( 1:20 , 4,5)
a

b <- matrix ( 21:40, 4, 5)
b

2 * a 
b - 5
2 * a + 3 * b

a+b
b-a
b / a
a * b

#Matrix/Data frame 자료구조 확인/변환

class ( iris )   #자료형이 matrix or data.frame인지
str(iris)

class ( state.x77 )  # 자료형에 따라 str의 결과가 다르게 나옴 
str( state.x77 )   #matrix 경우 str : 자료형, 행과열 정보, 데이터 내용


is.matrix ( iris)    #is 함수는 결과값 항상 논리값
is.data.frame ( iris)
is.matrix(state.x77)
is.data.frame( state.x77)

st <- data.frame ( state.x77)  
str(st)         # 매트릭스에서 데이터프레임으로 변환
head(st)        
class(st)
dim( st )       #관측치 50개 변수 8개 

head(st)   #Population가 변수 
Population #attach는 내가 변수이름을 직접 입력 원할 때 
attach(st) #변수 하나는 벡터 하나 
Population
detach (st) #attach 실행취소 
Population


iris.m <- as.matrix(iris[ , 1:4])  #데이터프레임의 1부터 4까지를 매트릭스로 변환 
head( iris.m)                      #as함수는 변환
class ( iris.m)
str( iris.m )        #150행 4열 
 =======================================   

CSV(Comma Seperator Values)_콤마로 파일 구분
TSV(Tab Seperator Values)_탭으로 파일 구분
>외부에서 자료받아올 때 대부분 상위 두개중 1 

Text file -> ASCII형식
Binary file -> Binary(이진법) 형식

#CSV File 내용읽기 ㅊ

setwd("C:/learnR")
air <- read.csv("airquality.csv",header = T)

#CSV가 생성되었을 때  자료 확인하는 과정 ★

class(air)
dim(air)
str(air)
head(air)
tail(air)
========================================   
name <- c("Hong","Kim", "Lee")
age <-  c(22,20,25)
gender = factor( c ("M","F","M"))
blood.type =factor(c ( "A", "O" , "B"))
person.info <- data.frame( name, age, gender, blood.type)
person.info 


setwd("C:/learnR")  
air <- write.csv(person.info, "person_info.csv",row.names = F)


20191202 5회차
*Day4 숙제 틀리거나 다시 해 볼 것들*
문2)
#8 apply( 데이터 프레임 이름, 행1 열2 , 함수)
#14 select 함수
#15 nrow와 subset 결합
# 치환을 굳이 안해도 되는 문제들 .. 
#18  [$] 연습 _ 안쪽 괄호가 가장 우선
#20~21  rowname만 뽑기

문3)
#4~5 rownames
#9 unique _중복될때 하나씩만 뽑기 

문4)
#4 한문장으로 하는 법 

문5)
#1~2 다시보기

===================================
pg.98
 JAVA => JDK_Java development-kit (Java 개발환경)
             JRE_Java Runtime Environment (Java 실행환경)
jdk 설치시 jre 자동 설치됨

Java
SE(Standard Edition)
EE(Enterprise Edition)
ME(Mobile Edition)


Rstudio 패키지 설치 함수
install.packages("xlsx")
install.packages("rJava")


Java 
1. Jdk 설치
2. D/S별 환경설정
환경변수  Path 에 JDK 설치 위치등록
=> 윈도우 표시 - 시스템 정보 - 고급시스템설정 - 환경변수 -
 시스템변수 - PATH- 편집 - 새로만들기 붙여넣기 - 붙여넣은것 맨위로
C:\Program Files\Java\jdk1.8.0_231\bin

명령프롬포트_ jvac - version

df.xlsx <-  read.xlsx ( file  = "airquality.xlsx", sheetIndex = 1 ,
                        encoding = "UTF-8")

*help 에서 인수값 검색할 때 값이 지정 되어있는건 default parameter로 필수값 x
eg. read.xlsx(file, sheetIndex, sheetName=NULL, rowIndex=NULL,
  startRow=NULL 
이렇게 Null로 되어있는 것들 ! 

Base_기본값이라서  다운 필요 x
 - read.table( )_일반 text file
 - read.csv( )_csv text file

xlsx _ 패키지를 설치해서 사용해야함
- read.xlsx - excel file


#which _ 위치값 찾는 함수 _몇번째에 위치하는가

score <- c( 76,84,69,50,95,6,82,71,88,84)
which( score == 69 )
which( score >= 85 )
max(score)
which.max(score)     #최대값이 있는  index
min( score )
which.min( score )

idx <-  which( score >= 60 )  #60보다 큰 변수
score[ idx ] <- 61  # 이 변수들을 일괄 61로 변경
score

head(iris)

idx <- which( iris [ , 1:4 ] > 5.0, arr.ind = TRUE )  #조건에 만족하는 행과 열의 인덱스 값_ vector일 때 불가능/ matrix o
idx

=======================================

Data 분석 절차 _ 현상을 분석하고 이면을 찾는 과정
1.문제 정의
2.Data 수집
3.Data 정제/ 전처리_불필요한 값을 제거
4.Data 탐색_탐색적 Data 분석
=>기본분석(변수들의 특성 , 평균, 최대값,최소값 등등)
5.Data 분석_ Data model구축(Machine Learning)
6.보고서

*Data 종류_ 1.1 + 2.1 / 1.1 +2.2 / 1.2 +2.1 / 1.2+2.2
1. 특성에 따른 분류
1.1 범주형 (Categorical data)_산술연산 불가능_factor형_숫자든 문자든 범위가 있는 것
eg. 남여, 혈액형
1.2 연속형(이산형) (Numerical data)_산술연산 가능
eg. 키, 몸무게, 나이

2.변수 개수에 의한 분류
2.1 일변량(Univaridate data)_변수가 1개 _Vector로 표현
2.2 다변량( Multivaridate data)_ 변수가 2개이상_Dataframe or matrix
     이변량( Bivaridate data)_변수가 딱 2 개

#단일변수 ( 일변량 ) 범주형 자료 탐색

favorite <- c("WINTER","SUMMER","SPRING","SUMMER",
                  "SUMMER","FALL","FALL","SUMMER","SPRING","SPRING")

favorite
class( favorite)
table( favorite)
table(favorite)
ds <-  table(favorite)
ds
barplot(ds,main = "favorite season")

ds.new <- ds[ c(2, 3, 1, 4)] #계절이름이 index의 이름 1 2 3 4 
ds.new
barplot( ds.new, main = "favorite season")
#barplot(벡터(table)이름, 그래프 제목 )

#pie는 원형 그래프
pie( ds, main = "favorite season")
pie( ds.new, main = "favorite season")


#숫자로 된 범주형 데이터 
favorite.color <-  c(2,3,2,1,1,2,2,1,3,2,1,3,2,1,2)

ds <-  table ( favorite.color) ; ds
barplot( ds, main = "favorite season" )
colors <- c("red", "orange" , " yellow")
names ( ds ) <-  colors ; ds
barplot(ds, main = "favorite season", col = colors )  #col = 색상부여 함수
pie ( ds, main = "favorite season", col = colors)


#단일변수(일변량) 연속형 자료

weight <- c(60,62,64,65,68,69) ; weight
weight.heavy <- c(weight,120) ; weight.heavy

#평균
mean ( weight ); mean ( weight.heavy)
#중앙값
median(weight) ; median ( weight.heavy)
#절사평균_ trim :하위/ 상위 x %만큼 제외하고 평균
mean( weight, trim = 0.2 )
mean( weight.heavy, trim = 0.2 )
#상위 두 자료형의 경우 평균값은 왜곡이 있다고 볼 수 있으며,  
#중앙값이나 절사평균은 의미가 있는값이라 할 수 있다..


#사분위수-데이터를 4등분 나눠서 범위별 값 추출 
#cf_2사분위(50%) 값은 중앙값과 동일
# 0% : 최소값 , 100% : 최대값
quantile( weight.heavy)
quantile( weight.heavy, (0:10 ) / 10 )

# Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 출력 함수 
summary( weight.heavy)  

## 산포 ( distrubution )

#분산
var(weright)
#표준편차
sd(weight)
#값의 범위 ( 최소값과 최대값)
range(weight)
#최대값과 최소값의 차이
diff( range ( weight ) )


==========================================
#histogram : 연속형 자료의 분포를 시각화_막대와 막대사이가 붙어있음 
#연속형 자료에서는 구간을 나누고 구간에 속한
#값들의 개수를 세는 방법으로 사용
cars
str ( cars )
dist <-  cars[ , 2 ]
dist
hist( dist, main = "Histogram for 제동거리", xlab = "제동거리", ylab = "빈도수",
          border = "black", col = "yellow", las = 2, breaks =5 )
#border:테두리 색 ,  las:xlabel의 출력 방향, break:막대수 



#상자그림 ( boxplot, 상자 수염 그림)
#사분위수를 시각화 하여 그래프 형태로 표시 
#상자 그림은 하나의 그래프로 데이터의 분포 
#형태를 포함한 다양한 정보를 전달
#자료의 전반적인 분포를 이해하는데 도움 
#구체적인 최소/최대/중앙값을 알기는 어렵다 

boxplot( dist, main = "자동차 제동거리 ")

boxplot.stats(dist)
boxplot.stats(dist)$stats # 정상범위 사분위수 
boxplot.stats(dist)$n     #관측치(row) 개수
boxplot.stats(dist)$conf  #중앙값 신뢰구간
boxplot.stats(dist)$out   # 이상치 (특이값)목록


##일변량 중 그룹으로 구성된 자료의 상자그림
#boxplot(물결 뒤쪽에 그룹으로 묶을 것들이 입력, 데이터셋 , 제목  )
iris
boxplot( Petal.Length~Species,
         data = iris, main = " 품종별 꽃잎의 길이" )

boxplot( iris$Petal.Length~iris$Species, main = " 품종별 꽃잎의 길이" )


##한 화면에 여러 그래프 작성 
par(mfrow = c(1,3)) # 1x3 가상화면 분할
barplot( table (mtcars$carb), main = "C",
         xlab =  "carburetors", ylab = "freq",
         col = "blue")

barplot(table ( mtcars$cyl ), main = "cyl",
        xlab = "cyl" , ylab = "freq",
        col = "red")
barplot ( table ( mtcars$gear ), main = "g",
          xlab = "gear", ylab = "freq",
          col = "green")
par(mfrow = c (1,1))  #가상화면 분할 해제

    20191203 6회차
숙제 검토 
#그래프 생성시 X/Y축 이름 설정
#*5. 가장 성적이 높은 과목의 이름을 출력하시오.
names( score[ score == max( score ) ] )

#재배열하는거 연습
ds <-  table(favorite)
ds
barplot(ds,main = "favorite season")  

ds.new <- ds[ c(2, 3, 1, 4)] #계절이름이 index의 이름 1 2 3 4 
ds.new
barplot( ds.new, main = "favorite season")

##교재 141pg 읽어보기 
#데이터셋에 따라 사용하는 데이터 분석 방법이 달라짐
#factor -> 범주형 -> 도수분포표 -> 막대그래프 ..
#num->연속형 -> 평균,분산,표준편차 -> 등등히스토그램
#=>숫자형이면서 범주형 성격을 가질 수 있다# 문4) #3.실리더
#어떠한 함수를 어떤 용도로 사용할 것인지가 중요!!
===========================================
#boxplot에서 중앙값 기준으로 위,아래값이 더 넓고 좁음 또한 알 수 있다. 

#다중변수 자료 탐색
#두 변수 사이의 산점도
#산점도 (scatter plot) -2변수로 구성된 자료의 분포를 알아보는 그래프 /
                            -관측값들의 분포를 통해 2변수 사이의 관계 파악

par(mfrow = c (1,1))

##Data 종류
 # 범주형 + 일변량 => vector
 # 연속형 + 일변량 => vector

# 다변량 , 이변량 =>  Matrix / Data frame

##중량과 연비의 관계(이변량) _ 중량이 무거우면 연비가 내려갈까? 
wt <- mtcars$wt
mpg <- mtcars$mpg
plot( wt,mpg , main = " 중량 - 연비 그래프" , xlab = "중량 ", 
        ylab = "연비" ,col ="red" , pch = 19, las = 1)
#pch: 점의 모양 ( 0부터 25까지 )

## 여러 변수들간의 산점도 (다변량)
#pairs _ 산점도는 대각선 모양으로 나왔을 때 상관관계가 높다

vars <-  c( "mpg","disp","drat","wt") #_벡터 생성 변수 4개
target <- mtcars[ , vars]             # matrix생성 (변수형이 동일해서 )
head( target )                  
pairs( target, main = "multi plots")  #대각선을 중심으로 대칭관계 _ x,y축이 변경된 상태 

#산점도 만드는 4가지 방법 _ 이변량

wt <- mtcars$wt
mpg <- mtcars$mpg
plot( wt,mpg , main = " 중량 - 연비 그래프" , xlab = "중량 ", 
      ylab = "연비" ,col ="red" , pch = 19 )

plot(mtcars$wt,mtcars$mpg, main = " 중량 - 연비 그래프" , xlab = "중량 ", 
      ylab = "연비" ,col ="red" , pch = 19)

plot( mtcars [, c("wt", "mpg")], main = " 중량 - 연비 그래프" , xlab = "중량 ", 
      ylab = "연비",col ="red" , pch = 19 )

plot( mpg~wt, data = mtcars , main = " 중량 - 연비 그래프" , xlab = "중량 ", 
      ylab = "연비" ,col ="red" , pch = 19 )


#그룹(factor)정보가 있는 두변수의 산점도
iris.2 <-  iris [,3:4]
iris.2
point <- as.numeric( iris$Species)  #문자열인 품종(Species)을 그룹화하기 위하여 숫자로 변환
point
color <- c("red" , " green" , "blue") #품종1 red /품종2 green / 품종 3 blue
plot(iris.2 , main = "Iris plot" ,
     pch = c( point), col = color [ point ] )

##상관분석 : 연속형	변수로	측정된	두	변수	간의	선형적(회귀선)	관계를	분석
#-1 <= 기본적인 상관계수(r) <= 1
#-1 음의 상관 : xy 반비례  _일반적으로 기준은 -0.5
#+1 양의 상관 : xy 비례    _ 일반적으로 기준은 +0.5

##맥주에 따른 혈중 알콜 농도 
beers <- c(5,2,9,8,3,7,3,5,3,5) 
bal <- c(0.1,0.03,0.19,0.12,0.04,0.0095,0.07,0.06,0.02,0.05)
tbl <- data.frame(beers ,bal )
tbl

plot(bal~beers, data = tbl)           # 산점도 

#회귀식을 구하는 식 lm : y = xw + b _ 연속값에대한 예측값 구하는 식
#y : 종속변수 , x : 독립변수 , w: weight , b : bias

 res <-  lm(bal~beers, data = tbl )   #회귀식
 res  #w와 b가 나옴 
abline ( res )                        #회귀선: 최적의 예측선 


# 상관관계가 강하냐 아니냐를 따져주는 상관계수 = r / cor 함수 

cor(tbl[ ,  1:2 ]) #이변량 상관계수_0.5 이상이므로 강한 상관관계로 볼 수 있다 (맥주/혈중알콜농도)
cor(iris[ , 1:4 ]) #다변량 상관계수 



#상관분석 순서 _ 절대적인 순서는 아님 
#1.상관분석 대상 변수선정
#2.산점도 작성( 관측값 분포 확인 ) : plot()
#3.회귀식 도출 :lm()   [lm: linear model]
#(회귀식 : 두 변수의 선형관계를 가장 잘 나타낼 수 있는 선의식)
#   (y= xw + b )
#4.회귀선을 산점도에 표시 : abline()
#(회귀선 : 관측값들의 추세를 가장 잘 나타낼수 있는 선 )
#5.상관계수 계산 ; cor()
#6.상관분석 결과 해석 



##시계열  Data - 선그래프 _ x축에 시간정보가 들어가는 data
month <-  1:12
late <- c(5,8,7,9,4,6,12,13,8,6,6,4)

#type : 선그래프의 모양/lty: 선의 모양 / lwd : 선의 두께

plot( month,late, main = "지각생 통계", type = "l",lty = 1 , lwd = 1,
      xlab = 'Month', ylab = " late cnt")

plot( month,late, main = "지각생 통계", type = "b",lty = 1 , lwd = 1,
      xlab = 'Month', ylab = " late cnt")

plot( month,late, main = "지각생 통계", type = "o",lty = 1 , lwd = 1,
      xlab = 'Month', ylab = " late cnt")

plot( month,late, main = "지각생 통계", type = "s",lty = 1 , lwd = 1,
      xlab = 'Month', ylab = " late cnt")


# 복수의 선 그래프 

late1 <- c(5,8,7,9,4,6,12,13,8,6,6,4)

late2 <- c(4,6,5,8,7,8,10,11,6,5,7,3)

#ylim(최소값,최대값) 축 범위 설정 

  plot(month,late1, main = "지각생 통계", type = "b",lty = 1 , col = "red",
      xlab = 'Month', ylab = " late cnt", ylim = c ( 1, 15)) 
lines( month, late2, type = "b", col = "blue")   #lines 함수를 이용하여 선그래프 추가 


##자료 탐색 실습 - 탐색적 데이터 분석

##0단계 : 문제정의
##1단계 : 분석 대상 데이터셋 준비
#BostonHousing  데이터셋 (mlbench pac.)

install.packages("mlbench")
library (mlbench)
data("BostonHousing")

#crim : 1인당 범죄율
#rm : 주택 1가구당 방 수
#dis: 보스턴 5개 지역센터까지의 거리
#tax : 재산세율
#medv: 주택가격
class (BostonHousing)
dim (BostonHousing)
str (BostonHousing)
head (BostonHousing)
tail (BostonHousing)
myds <- BostonHousing [ , c( "crim", "rm","dis","tax" ,"medv" ) ]
myds

BostonHousing

##2 단계 : 파생변수 추가  : grp 변수 추가 ( 주택 가격 상중하)
# myds$medv의 i 번째 요소에 있는 값이 25.0 이상이면 grp 에 H/ 17 이하 L / 나머지는 M
grp <- c()
for( i in 1:nrow ( myds)){ 
  if( myds$medv [i] >= 25.0 ){
    grp [i] <- "H"
  } else if ( myds$medv [ i ] <= 17.0 ){
    grp [i] <- "L"
  } else {
    grp [i] <- "M"
      }
  }
  
grp <- factor (grp)
grp <-  factor( grp, levels =c( "H", "M", "L")) #레벨순서  ★★★★★★★★★★★★★★★★★★★

myds <-  data.frame ( myds, grp)
head ( myds)

##3단계 : 데이터셋의 형태와 기본적인 내용 파악 

str(myds)
head(myds)
table(myds$grp)


##4단계  : 히스토그램에 의한 관측값의 분포 확인

par( mfrow = c ( 2, 3))  #2x3 그래프 가상화면 
for( i in 1:5) {
  hist( myds[ , i ],
        main = colnames ( myds )[ i ],
        col = "yellow")
}

par( mfrow = c ( 1,1)) #가상화면 복귀 


##5단계  : 상자그림에 의한 관측값의 분포 확인 


par( mfrow = c ( 2, 3))  #2x3 그래프 가상화면 
for( i in 1:5) {
  boxplot ( myds[ , i ],
        main = colnames ( myds )[ i ])
}


##6단계 : 그룹별 관측값 분포 확인 
boxplot(myds$crim~myds$grp, main = " 1인당 범죄율 ")   #grp 가 그룹화 ( factor형 )

boxplot(myds$rm~myds$grp, main = " 방의 개수 ")

##7단계 :  다중 산점도를 통한 변수간 상관관계 확인

pairs( myds [ , -6] ) #6번째 변수는 제외하고 보기 (Factor형 grp 제외)

##8단계 : 그룹 정보를 포함한 변수 간 상관관계 확인 

point <- as.integer(myds$grp)

color <-  c( "red", "green", "blue" )
pairs( myds[ , -6 ], pch = point, col = color [ point ]) #pch 점의모양 


##9단계: 변수간 상관계수 확인 
cor ( myds[ , -6 ] )

# > rm과 medv가  상관관계가 있음을 확인가능


#Data 이해
#1.Data set에 대한 이해
#2.문제 정의 검증
#3.문제 정의에 대한 1차 결과 파악 

#20191204 7회차 
교재 : 172-233 pg
#복습할 것 

#1 . cor 표현방법 
#cor(iris[ , 1:4 ])
#cor( income, period )
#plot 과 pairs

#==============================
  
##Data 분석 절차 _ 현상을 분석하고 이면을 찾는 과정
#1.문제 정의
#2.Data 수집
#3.Data 정제/ 전처리_불필요한 값을 제거
#4.Data 탐색_탐색적 Data 분석
# =>기본분석(변수들의 특성 , 평균, 최대값,최소값 등등)
#5.Data 분석_ Data model구축(Machine Learning)
#6.보고서

##Data preprocessing (데이터 전처리)
#원시 자료에 대하여  Data 정제/가공을 수행하여 분석에 적합한 형태로 만드는 과정

##Data 정제 ##

#1.결측치에 대한 처리(Missing value)
 #NA 값이 없는것_ 데이터를 읽을 수 없다
 #NA가 있으면 산술 연산 불가능

#2.이상치에 대한 처리
 #들어가면 안되는 값이 포함
 #eg. 나이에 마이너스값 등 

#↓↓↓↓↓

##Data 가공 ##
#정렬
#추가 
#필터링
#집계  
#병합

#==========================================
  
#결측치에 대한 처리_ 결측치가 해당 데이터셋에 어떠한 의미인지 파악 必 
#1. rational approach 
 #계산 공식을 알 때 결측치를 채워주는 방법
 #자주사용됨

#2. listwise deletion
 #결측치가 들어가 row를 삭제 
 #처리방법은 쉬우나 분석가능한 데이터의 양이 줄어듬 _ 분석결과에 영향을 미칠 수 있다
 #자주사용됨

#3. pairwise deletion
 # A B 의 상관관계를 따져서 임의로 값을 넣거나 삭제
 # 분석결과에 왜곡이 있을 수 있음 

#4. 단순 대입법
 # NA값에 변수를 대표할 수 있는 값 대입 (평균 값 / 중앙값) 
 # 자주사용됨

#5. 다중 대입법
 #결측치에 대표값을 바꿔가며 대입 =>  5~10번이상
 # 그 결과 값들을 다시 하나의 자료로 만듬
 # 데이터의 왜곡을 줄일 수 있다 

#========================================

##결측치 처리

# vector의 결측치 처리 

z <- c(1,2,3,NA,5,NA,8)
sum( z )       #결측치가 있는지 확인하는 과정 _ 결측치가 포함된 변수는 산술연산 불가능 결과 무조건 NA
is.na(z)       #is 함수는 결과값이 논리값 #TRUE = NA
sum( is.na(z)) #결측치 개수  (TRUE = 1 ,FALSE = 0 으로 자동 변경)
sum(z,na.rm = TRUE) 
#모든 산술연산은 na.rm 함수를 모두 갖고 있다.
# na.rm =>결측치 제외 유무 ( TRUE = 제외 , FALSE = 포함)


##결측치 대체 및 제거

#단순대입법
z1 <- z
z2 <- c(5,8,1,NA,3,NA,7) 
z1[ is.na(z1)] <- 0      #[ ]와 ()의 우선순위는 동일 / 
z1                       #안쪽부터 계산해서 ()먼저 계산
z1

# Listwise deletion
z3 <- as.vector(na.omit(z2))  #na.omit = >결측치 데이터 삭제 함수 
z3                         

###Matrix / Data Frame 결측치 처리###

x <- iris
x[1,2] <- NA
x[1,3] <- NA
x[2,3] <- NA
x[3,4] <- NA
head(x)

## Matrix / Data Frame 열별 결측치 확인

#1.for문 이용 

for( i in 1:ncol(x)){             #1부터 변수(col)수_5 번 반복
  this.na <-  is.na(x[ , i ])
  cat( colnames(x)[i],
       "\t", sum( this.na),       #sum ( 결측치 True/false )
       "\n")
}


#2.apply() 이용.1 _ apply(dataframe,행/열,함수)  행:1 / 열:2

col_na <- function( y ){         
  return ( sum ( is.na(y)))
}
na_count <- apply(x,2,col_na)   #열방향(2)으로 
na_count


#2.apply() 이용.2

na_count <- apply(x,2,
                  function(y) sum( is.na ( y)))   #funtion(y) sum( is.na )(y) : 익명함수 
na_count  #각변수의 결측치 수 

##_ 교재에 없는 부분 참고용##

barplot(na_count[ na_count > 0])

install.packages("VIM")
require( VIM)

#결측치 자료 조합 확인용 시각화 도구
aggr(x, prop = FALSE , numbers = TRUE)

x
#두개의 변수간의 결측치 관계 확인 시각화 도구
marginplot( x[c("Sepal.Width","Petal.Width")],
            pch = 20 , col =c ("darkgray","red","blue"),las = 1)  #빨간점이 결측치 

#=========================================================


#Matrix/ Data Frame 의 행 (data)별 결측치 확인
rowSums( is.na(x))
sum(rowSums (is.na(x)) > 0) #결측치가 포함되어있는 행의 수 

sum(is.na(x)) #행 열 구분 없이 전체 결측치 4 


#결측치를 제외한 새로운 데이터셋 생성

head(x)
x[ !complete.cases(x), ]  #NA가 포함된 행출력
y <- x[ complete.cases(x), ]  #complete.cases () =결측치가 포함된 행 제외 

head ( y )


#이상치(outlier)
#1.논리적으로 성립되지않는 값_눈으로 직접 찾아야함 
#2.상식적으로 용인되지않는 값_상자수염을 통해 이상치를 찾을 수 있다

# 특이값, 이상치 ( outlier )

st <- data.frame(state.x77)
st
summary(st$Income)
boxplot(st$Income)
boxplot.stats(st$Income)$out
                 
# 특이값 처리  : NA로 변환 후 결측치 처리 방법 이용
out.val <- boxplot.stats(st$Income)$out
st$Income[ st$Income %in% out.val] <- NA  #  %in% 연산자 : 포함되어있다면 
head(st)
newdata <- st[complete.cases(st), ]
head(newdata)

##Data 가공
 #정렬
 #추가 
 #필터링
 #집계  
 #병합
 
#데이터 가공
#
#데이터 정렬
#Vector

v1 <- c(1,7,6,8,4,2,3)
order(v1)
v1 <- sort(v1)
v1
v2 <- sort(v1,decreasing = T)  #decreasing = True:내림차순  / 설정안하면 오름차순
v2


#Matrix / Data Frame 정렬

head( iris)
order (iris$Sepal.Length) #결과값은 vector_첫번째행이 정렬했을때 14번째
iris[ order(iris$Sepal.Length), ] #Ascending
iris[ order ( iris $ Sepal.Length,decreasing = T), ] #Des
iris.new <- iris[ order ( iris$Sepal.Length), ]
head( iris.new)
iris[ order ( iris$Species, decreasing = T ,
      iris$Sepal.Length) , ]  #정렬기준을 2개 설정



#데이터 분리
iris
sp <-  split( iris, iris$Species) #iris 함수를 Species별로 분류 
sp
summary( sp )

sp$setosa
summary( sp$setosa )

#데이터 선택
subset( iris , Species == "setosa")
subset( iris , Sepal.Length > 7.5 )
subset( iris , Sepal.Length > 5.1 & Sepal.Width > 3.9 )
subset( iris , Sepal.Length > 7.6, 
        select = c ( Petal.Length, Petal.Width))

##데이터 Sampling

#1.비복원 추출
#한번 추출한 샘플데이터를 다음 샘플링할 때 제외시킴
#2.복원 추출
#한번 추출된 샘플데이터라도 다음 샘플시 다시 포함시킴 _ 같은 데이터가  샘플링 될 수 있음


#_숫자를 임의로 추출(Vector)
x <- 1:100
y <- sample( x, size = 10 , replace = FALSE)   # replace = FALSE (비복원)  TRUE(복원)
y

# dataframe에서 행을 임의로 추출
idx <-  sample ( 1: nrow ( iris ) , size = 50 , replace = FALSE)
idx
iris.50 <- iris [ idx, ]
iris.50
dim( iris.50 )
head( iris.50)


sample( 1:20, size = 5)
sample( 1:20, size = 5)
sample( 1:20, size = 5)

#set.seed (100)_ 100은 임의값  동일한 값을 샘플로 사용하고 싶을 때 
set.seed(100)  
sample( 1:20, size = 5)
set.seed(100)
sample( 1:20, size = 5)

##데이터 조합

#combn : combination (조합할 수의 범위 , 조합할 수의 범위)
combn( 1:5,3)   #1부터 5까지 3개를 뽑겠다 그 조합을 출력 
#10개만 출력되지만 조합이 더 많을 수 있따 


x = c ("red", "green", "blue", "black", "white")
com <- combn( x,2)
com


for( i in 1:ncol( com )) {
  cat( com[ ,i], "\n")
}


#데이터 집계    _ aggreagate는 집계함수_(집계할 대상 , 집계하는 기준 , 함수 ) 
agg <-  aggregate( iris[ , -5],
                   by = list ( iris$Species),
                   FUN = mean) ; agg

agg <-  aggregate( iris[ , -5],
                   by = list ( iris$Species),
                   FUN = sd) ;agg


head( mtcars)                                                           
agg <- aggregate(mtcars, by = list ( cyl= mtcars$cyl,         #_ by = 그룹으로 묶어라 그중에서 최고값을 구해라라
                                     vs = mtcars$vs),FUN = max)
agg


##데이터 병합 
x <- data.frame(name = c( "a","b","c"),
                mat = c (90, 80 , 40)) ;x


y <- data.frame( name = c( "a", "b", "d"),
                 korean = c(75,60,90));y

z <- merge(x,y,by = c("name"))  #공통변수일 경우 BY 생략 가능 
z            #이름이 같은 변수만 출력 
   

merge(x,y)
merge(x,y,all.x = T)  # x내용은 다 들어옴 _변수 추가 
merge(x,y,all.y = T)  # y내용은 다 들어옴 _변수 추가 
merge(x,y,all= T)     #단순 merge 

#두개의 다른 데이터프레임에 같은 변수명이 하나도 없을 때( name != sname)
  
x <- data.frame(name = c( "a","b","c"),     
                  mat = c (90, 80 , 40)) ;x


y <- data.frame( sname = c( "a", "b", "d"),
                 korean = c(75,60,90));y

merge( x, y, by.x = c ("name"),by.y = c("sname"))


#
###dplyr package_데이터 가공시 가장 자주 사용
#

install.packages("dplyr")
library(dplyr)

 #   %>% :pipe 연산자_단축키 ( 왼쪽 ctrl+ 왼쪽 shift +  M)
 #  A %>% B : A에 입력된것을 출력해서 그것을 다시 B에 입력  

df <- data.frame( var1 = c (1,2,1),
                  var2 = c(2,3,2))

df

#rename() : 이름변경  (함수, 바꿀이름 = 기존이름)

df <- rename ( df, v1 = var1, v2 = var2) 
df

#파생변수 추가 
df$sum <- df$v1 + df$v2
df

df[2,1] <- 5
df

df <- data.frame( id = c (1,2,3,4,5,6),
                  class = c(1,1,1,1,2,2),
                  math = c( 50,60,45,30,25,50),
                  english = c(98,97,86,98,80,89),
                  science = c(50,60,78,58,65,98))
df


#filter(): 행 추출

df %>% filter(class == 1 )
df %>% filter(class == 2 )
df %>% filter(class != 2 )
df %>% filter(class != 2 )

df %>% filter(science > 70)
df %>% filter(math < 50 )

df %>% filter( class ==1 & math >= 50 )
df %>% filter( math >= 50 | english >= 90 )
df %>% filter( class %in% c(1,3,5))

class1 <- df %>% filter( class == 1 )
class2 <- df %>% filter( class == 2 )
class1
class2

#select() : 변수 추출

df %>% select ( math )
df %>% select( science )

df %>% select ( class, math , science)

df %>% select( -math)

#dplyr 함수 조합

df %>% 
  filter( class == 1) %>% 
  select ( science )

df %>% 
  select( id, science ) %>% 
  head

df %>% 
  select( id, science ) %>% 
  max

#arrange() : 정렬

df %>% arrange ( science )  #오름차순
 
df %>% arrange(desc(science)) #내림차순 

#mutate() : 파생변수 추가
df %>% 
  mutate ( total = math + english +science) %>% 
  head
library(dplyr)

df %>% 
  mutate(total = math + english + science, 
         average = (math + english + science)/3) %>% 
  head

df %>% 
  mutate( grade = ifelse( science >= 60, "pass", 'fail')) %>% 
  head

df %>% 
  mutate(total = math + english + science, 
         average = (math + english + science)/3) %>% 
  mutate( grade = ifelse(average >= 90, "pass",ifelse(average<60,"fail","normal"))) %>% 
  head

df %>%
  mutate(total = math + english + science, 
         average = (math + english + science)/3) %>% 
  arrange(desc(average)) %>% 
  head

# 원 함수의 값을 계속 바꾼다면 초기의 입력순서를 알 수 없으므로 새 함수로 치환 #

#eg_)
df.sort <- df %>%
  mutate(total = math + english + science, 
         average = (math + english + science)/3) %>% 
  arrange(desc(average)) %>% 
  head
df.sort

#summarise() : 집단별 요약
#group_by() : 집단별 나누기 

df %>%  summarise( mean_math = mean ( math ))

  df %>% 
  group_by( class ) %>% 
  summarise( mean_math = mean ( math ),
             mean_english = mean (english),
             mean_science = mean ( science),
             n = n () )  # n = n (인수없음) => 빈도수 계산하는 함수 
  
  ## A tibble: 2 x 5  2행5열 
  ##<dbl>  :double 숫자형
  ##summarise함수를 할 때에는 보통 그룹화를 한다 
  
 
  str(mpg) install.packages( "ggplot2")
  str( ggplot2:: mpg)   # A:: => A가  가지고있는_LIBRARY를 통한 패키지 로드없이 사용  (패키지명::데이터셋이름 )
  mpg <- data.frame(ggplot2::mpg)
  mpg
  dim(mpg)
  head(mpg)
  View(mpg) #_대문자
  
mpg %>% 
  group_by( manufacturer, drv ) %>% 
  summarise( mean_cty = mean( cty ) ) %>% 
  head( 10 )
   
  mpg %>% 
    group_by( manufacturer) %>% 
    filter( class == "suv") %>% 
    mutate(tot = ( cty +hwy )/ 2) %>% 
    summarise( mean_tot = mean( tot)) %>% 
    arrange(desc(mean_tot)) %>% 
    head(5)
    
    
###데이터 합치기
    
# left_join(): 가로로 합치기( 변수 추가 )
#inner_join ():가로로 합치기(변수 추가) 
#full_join():가로로 합치기(변수 추가)
#bind_rows(): 세로로 합치기( data 추가)
  
df1 <- data.frame( id = c( 1,2,3,4,5),
                     midterm= c(60,80,70,90,85)) ; df1
df2 <- data.frame(  id = c( 1,2,3,4,5),
                       final = c(60,80,70,90,85)) ; df2

total <- left_join(df1,df2,by = "id") ; total
    

df1 <- data.frame( id = c ( 1,2,3),
                   address = c ( "서울","부산","제주"),
                   stringsFactors = F)  # 해당 문자열을 factor로 바꾸지마라 _ stringsFactors = F

df2 <- data.frame(id =c (1,2,4), gender = c ("남","여","남")) #둘중 왼쪽 df1 기준 추가 

df_left <- left_join(df1,df2,by = "id" )
df_left

df_inner <-  inner_join ( df1,df2, by = "id")  #둘중 공통된것만 추가 (merge와 동일)
df_inner

df_full <-  full_join(df1,df2,by = "id")   #  둘다 출력 
df_full




df1 <- data.frame( id = c( 1,2,3,4,5),
                   test= c(60,80,70,90,85)) ; df1
df2 <- data.frame(  id = c( 1,2,3,4,5),
                    test = c(60,80,70,90,85)) ; df2

df_all <-bind_rows(df1, df2)
df_all


install.packages("psych")
library(psych)


summary(mtcars)
describe(mtcars)  #n 관측치_ summary 보다 더많은 요약정보  

install.packages("descr")
require(descr)

df <- data.frame( id = c( 1,2,4 ),
                  
                  gender = c ("남","여","남"))
                  
                  table = (df$gender) #TABLE은 도수분포표
                  
                  freq( df$gender) #도수분포표 + 막대그래프까지 동시에 실행 //DESCR 패키지에 있다
                  freq(df$gener, plot = F) #PLOT = F 하면 막대그래프 안나옴 

20191205 8회차

Day7 
ncol = 열의 갯수 세는 함수 

%>% 
Filter은 행출력
Select는 열 출력

join함수는 공통변수가 있을 때 사용

merge의 기본은 a,b둘다 공통적으로 가진 것을 합치는 것
merge는 공통변수가 없을 떄 
 
====================================================

문제 2 )
	제주 대중교통 현황을 분석한다. - 과연 만족도 1위가 맞는가?

 각 조 해당 번호의 조원이 해당 문제에 대하여 분석한다.	
* 문제에 대한 정의를 구체화 시켜서 분석한다.
  현재의 현황, 국내 타 지역과의  비교, 장/단점등의 분석 목적을 설정하여 분석한다.
	
* 자료 수집 참고 site
	공공 데이터 포털 : https://www.data.go.kr
	제주 데이터 허브 : https://www.jejudatahub.net
	기상 자료 개방 포털 : https://data.kma.go.kr/cmmn/main.do
	SKT 데이터 허브 : https://www.bigdatahub.co.kr/index.do _통화량
	네이버 데이터랩 : https://datalab.naver.com

* 2019년 12월 6일 오후 12시까지 제출		
* 분석 결과 보고서는 PPT로 작성한다.
* 분석 결과 보고서는 문제 정의, 분석 과정, 분석 결과, 참고 자료 및 도구순으로 작성한다.
* R Script file의 처음에 주석으로 본인 이름과 작성일/제출일 기록
* 분석 결과 보고서와 R script file, 수집한 자료를 "영문본인이름_조_제출일날짜.zip" 이름으로 
  압축하여 제출한다.

===============================================================


분석할 때 주의점

1. 전후 관계 설명 
2. 설치년도 대비 범죄율 추이
3. 분석 이유 eg(서울과 비교한다면 서울과 비교하는 이유 _데이터 기반) 
4. 표와 분류 순서 match 필요 
5. 데이터가 일치해야 신뢰도 ↑
6. 분석범위는 너무 커도 좋지않음
7. 최근 자료 必 if not 신뢰성 ↓
8. 실제 자료 데이터는 발표용에는 넣는것이 아님
9. 데이터분석은 자의적으로 x
10. 분석하고자 하는 주제에 대한 현황 분석이 선행되어야함
11. 분석 년도 /갯수 맞추는 것이 좋다 4
12. 문제정의가 처음으로 진행되어야함 !
13. 지역별 산업분포

20191209 9회차

*분석 목적을 명확하게 & detail하게 조사 
   eg.인구가 증가했다면 왜 증가했는지 
*수치정보와 그에대한 해석이 필요( 단순 그래프 나열 x)
*그래프 부가설명이 ppt에 간략하게_자료만 보는 사람을 고려

Markdown 형식_보고서 작성

##20191209 10일차 

#https://www.tidyverse.org/packages/

install.packages( "tidyverse")
library(tidyverse)  # library와 require 동일한 기능 

#tibble 은 dataframe 개선한 것 


dim(mpg)
str(mpg)
head(mpg)
View(mpg)

#함수를 기본적으로 2개 
#ggplot은  기본함수 / LAYER 방식 eg) ggplot 깔고 geom_histogram깔고 theme깔고 
#반드시 플러스 연산으로 함수 연결 必 
#그래프 함수는 다 geom으로 시작 
#ggplot 은 data frame 으로 실행 해야함
#그래프를 그릴 때에는 data와 mapping은 필수값 *
ggplot( data = mpg ) +
geom_point( mapping = aes( x = displ, y = hwy)) #산점도 그리는 함수 
                                                #mapping은 x y 지정 #mapping  은 생략가능 

month <- c(1,2,3,4,5,6)
rain <- c(55,50,45,50,60,70)
df <- data.frame(month,rain)

ggplot(df,aes(x = month, y = rain))+  #aes안에 x와 y 좌표 설정해주기 _ ggplot에 넣거나 그래프 함수 안에 넣거나 상관없음 
    geom_bar(stat = "identity", #막대높이 
             width = 0.7 ,      #막대폭
             fill = "steelblue")  # 그래프 채움 색 

##가로 그래프 
#ggtile < 제목 설정
#labs  x,y축 이름 설정
#theme  ggtile의 테마
#coord_flip()  그래프를 옆으로 눕혀라 

ggplot(df,aes( x = month, y = rain))+
    geom_bar(stat = "identity", 
             width = 0.7 ,      
             fill = "steelblue")+  
ggtitle("월별 강수량") +
theme(plot.title = element_text(size =25,
                                face = "bold",
                                colour = "steelblue")) +
labs( x= "월", y ="강수량") + coord_flip()
    
##ggplot 히스토그램 
#bindwidth은연속형에대하여  x단위를 어떤 단위로 카운트 할것인지 
ggplot(iris, aes( x = Petal.Length))+
    geom_histogram(binwidth = 0.5)  


#fill에다가 종류별로 색을 넣기 위해서 _  iris의 Species 는 범주형 
#color는 막대의 경계선의 색 
#position 품종별로 한그래프에 그릴지,각각 그릴지 _ dodge는 따로 그리는 명령
#legend.position은 범례의 위치 

ggplot( iris, aes( x= Sepal.Width, fill = Species , 
                   color=Species )) +
    geom_histogram(binwidth = 0.5, position = "dodge") +
    theme( legend.position = "bottom")


##ggplot2 Scatter Chart _ 
#geom_point _산점도 

ggplot( data = iris, mapping = aes( x = Petal.Length, 
                                     y = Petal.Width ) ) +
    geom_point()

# mapping의 위치는 상관없다 _

ggplot( data = iris ) +
    geom_point( mapping = aes( x = Petal.Length, 
                                 y = Petal.Width ))

##산점도
# color를 aes안에 넣으면 색 지정 가능 

ggplot( data = iris, mapping = aes( x = Petal.Length, 
                                    y = Petal.Width,
                                    color = Species,
                                    shape = Species )) +
    geom_point(  
        size = 3) +
    ggtitle("꽃잎의 길이와 폭 ") +
    theme( plot.title = element_text(size = 25,
                                     face = "bold",
                                     colour = "green"))

##ggplot, Boxplot
#boxplot은y만 지정 , 가로폭은 의미없음 
#
ggplot( data = iris, mapping = aes(y= Petal.Length))+
    geom_boxplot(fill = "yellow")


#한그래프 안에 세개의 box plot 
#aes의 안에는 xy좌표나 그것들 성질 등등
ggplot( data = iris, mapping = aes(y= Petal.Length, fill = Species))+
    geom_boxplot()

##ggplot Line Chart
#선그래프_시간정보가 포함된 데이터에 자주사용됨

year <- 1937:1960
cnt <- as.vector(airmiles)
df <- data.frame(year,cnt)

head(df)

ggplot(df,aes( x = year, y = cnt)) +
    geom_line(col = "red")

#ggplot 작성 graph 꾸미기
str(economics)

##사선
#intercept : y 절편 값
#slope :기울기 
#abline :사선을 그을 때 쓰는 함수 
ggplot( economics, aes( x= date, y = psavert))+
    geom_line() + 
    geom_abline( intercept = 12.18671,
                 slope = -0.0005444)
##평행선_시계열 데이터에 많이 사용됨 
#hline은 가로 선_ 기준 치 
#평균 기준으로 가로선 
ggplot( economics, aes( x = date, y = psavert))+
    geom_line()+
    geom_hline(yintercept = mean( economics$psavert))

#vline 세로선_ 기준 날짜 
#psavert의 값이 최소가 되는 날짜 

x_inter <-  filter(economics,
                   psavert == min ( economics$psavert))$date
ggplot( economics, aes( x = date, y = psavert))+
    geom_line() +
    geom_vline( xintercept = x_inter)

##텍스트 추가
#geom-text _ aes : 맵핑 해주는 역할 , label : 출력할 값 ,vjust= 0 숫자 출력 위치  
#0은 우측상단, +1: 좌측하단 , -1:우측 멀리상단 
ggplot(airquality,aes ( x = Day, y = Temp))+
    geom_point()+
    geom_text ( aes ( label = Temp,
                      vjust = 0,
                      hjust = 0))

##영역 지정 및 화살표 표시
#annotate _ rect은 모양 , alpha는 투명도  0~1사이 1에 가까울수록 불투명 
ggplot( mtcars, aes( x= wt, y = mpg))+
    geom_point()+
    annotate("rect",
             xmin = 3, 
             xmax = 4,
             ymin = 12,
             ymax = 21,
             alpha = 0.5,
             fill = "skyblue") +
    
annotate("segment", x= 2.5 , xend = 3.7,        #화살표 표시 추가
         y = 10, yend = 17, color = "red",      #segment _ 화살표
         arrow = arrow() )  +                   #화살표 길이 _x,xend,y,yend
    annotate( "text", x = 2.5, y = 10, label = "point")     #텍스트 추가 



#https://ggplot2.tidyverse.org/reference/index.html
#document users guide reference  _사용 설명서
#document reference guide reference _ 명령/ 함수 설명서 

#ggplot usage guide _ https://r4ds.had.co.nz/data-visualisation.html
#트리맵 _ https://rpubs.com/brandonkopp/creating-a-treemap-in-r

##treemap
install.packages("treemap")
library(treemap)

data("GNI2014")
dim(GNI2014)
str(GNI2014)
head(GNI2014)
view(GNI2014)

treemap( GNI2014, index = c( 'continent', 'iso3'), #계층구조_ 대륙 밑에 국가별로 계층화해라 
vSize ='population',                               #타일크기_ 인구가 많으면 타일이 크게해라
vColor = 'GNI',                                    #타일색깔_ GNI에 따라 색을 결정 
type = 'value',                                    #타일컬러링방법_ vcolor에서 정한 데이터의 value를 통해 
bg.labels = 'yellow',                              #레이블배경색_ 글씨 배경색
title = "World's GNI")                             #제목

st <- data.frame(state.x77)
st <- data.frame(st,stname = rownames(st))


treemap( st,
         index = c( "stname" ),
         vSize = "Area",         
         vColor = "Income",
         type = "value",
         title= "미국 주별 수입")


##산점도에 Bubble 추가 ( BUBBLE CHART)
#보통 산점도에 사용함 
symbols(st$Illiteracy,st$Murder,        #원의 xy 좌표
       circles = st$Population,         #원의 반지름
       inches = 0.3,                    #원크기 조절값
       fg = "white",                    #원 테두리 색
       bg = " lightgray",               #원 바탕색
       lwd = 1.5,                       #원 테두리선 두께
       xlab = "rate of Illiteracy", 
       ylab = "crime( murder) rate",
       main = "Illteracy and Crime")             

text(st$Illiteracy,st$Murder,           #텍스트출력 xy좌표
     rownames( st ),                    #출력할 text
     cex = 0.6,                         #폰트크기
     col = "brown")       #폰트컬러

##R 그래프 갤러리 : https://www.r-graph-gallery.com/index.html
##heatmap , map , 3d , spider 자주 사용됨 
#bubble 연습 
#============================================
# Libraries
library(ggplot2)
library(dplyr)
library(plotly)
library(viridis)
library(hrbrthemes)

# The dataset is provided in the gapminder library
library(gapminder)
data <- gapminder %>% filter(year=="2007") %>% dplyr::select(-year)

# Interactive version
p <- data %>%
    mutate(gdpPercap=round(gdpPercap,0)) %>%
    mutate(pop=round(pop/1000000,2)) %>%
    mutate(lifeExp=round(lifeExp,1)) %>%
    
    # Reorder countries to having big bubbles on top
    arrange(desc(pop)) %>%
    mutate(country = factor(country, country)) %>%
    
    # prepare text for tooltip
    mutate(text = paste("Country: ", country, "\nPopulation (M): ", pop, "\nLife Expectancy: ", lifeExp, "\nGdp per capita: ", gdpPercap, sep="")) %>%
    
    # Classic ggplot
    ggplot( aes(x=gdpPercap, y=lifeExp, size = pop, color = continent, text=text)) +
    geom_point(alpha=0.7) +
    scale_size(range = c(1.4, 19), name="Population (M)") +
    scale_color_viridis(discrete=TRUE, guide=FALSE) +
    theme_ipsum() +
    theme(legend.position="none")

# turn ggplot interactive with plotly
pp <- ggplotly(p, tooltip="text")
pp

# save the widget
# library(htmlwidgets)
# saveWidget(pp, file=paste0( getwd(), "/HtmlWidget/ggplotlyBubblechart.html"))

#============================================

                  

#20191210
#DAY 10 hw 
#문제6번 _ 범주형이여야 그룹을 나눌 수 있다 _ 범례 위치 설정 보기
#문제7번 _ 시간 정보는 선그래프를 자주 사용 
#문제 8번 _1)
#- us로 다시 데이터 프레임 설정해준 부분
#- type = value  다시 보고 의미 확인 

#데이터 유형에 따라 어떤 시각화 도구를 쓰는지 중요 

##Open source
#주의점
#1.BUG가 존재 가능
#2.저작권 확인 *
#GPL,LGPL  :무료, 소스 공개 의무 O
#APL,BSD,MPL : 소스 공개 의무 X



##모자이크 함수
#범주형 + 다중변수(= 두개이상의 범주형)일때 빈도수 확인시 모자이크 사용
#https://www.rdocumentation.org/packages/mosaic/versions/1.5.0

#mosaic plot
#다중변수 범주형 데이터에 대한 각변수의 그룹별 비율을 '면적'으로 표시

View(mtcars)
str(mtcars)
head(mtcars)
mosaicplot( ~gear + vs,   #대상변수 ( ~x축 + y축 )
           data = mtcars, #데이터셋
           color = TRUE,  #Y축 변수의 그룹별 음영 다르게 표시 
           main = "Gear and Vs") #제목
# 색상 넣기 
mosaicplot(~gear + vs , data = mtcars,
           color = c( "green","blue"),
           main = " Great and VS")

#테이블 함수 만들고 그걸 모자이크플롯_ 데이터 자체가 교차형
tbl <- table(mtcars$gear,mtcars$vs)
tbl 

mosaicplot(tbl,color = T, main = "gear and vs")   


##차원 축소 (dimension reduction)
#4차원 = > 3차원 차원축소시 데이터 손실
#4차원은 표현하기 어렵기 때문에 차원축소 필요 
#차원 축소 기법 : t -sne 기법

install.packages("Rtsne")
library(Rtsne)
library(tidyverse)

ds <- iris[ , -5 ]  #변수 4개에 대하여 표현 - 4차원
ds

##차원축소 
#중복 데이터 제거 

dup = which(duplicated (ds))
dup #143  _ 143행에 중복데이터가 있다는 뜻

ds <- ds[-dup,]  #중복데이터 제거 
ds.y <- iris$Species[-dup] #품종에 대해서도중복데이터 제거 必_나중에 표현 해야
ds.y

##차원 축소 수행 - t-SNE 실행

tsne <- Rtsne( ds,                 #차원축소 대상 데이터셋
               dim = 2,         #축소할 차원 2or3차원
               perplexity = 10 )  #데이터 샘플링을 수행할 샘플의 횟수는 :
                      #(대상데이터수) /3 보다 작게 지정 :149 /3 보다 작은값

tsne <- Rtsne(ds,dim = 2, perplexity = 10)
tsne

View(tsne)
#차원축소시 데이터 손실은 발생하지만 4차원에대한 분석 불가능하기 때문에 감수

#차원축소 결과 시각화 

df.tsne <-  data.frame( tsne$Y )
head( df.tsne )

ggplot( df.tsne, aes( x= X1,y = X2 ,color = ds.y))+
    geom_point( size =2)


install.packages(c("rgl", "car"))
library(car)
library(rgl)
library(mgcv)

tsne <- Rtsne( ds, dims = 3, perplexity = 10)
df.tsne <- data.frame(tsne$Y)
head( df.tsne )

scatter3d(x = df.tsne$X1, y = df.tsne$X2,
          z = df.tsne$X3)
 
points <-  as.integer(ds.y)
color <- c("red","green","blue")
scatter3d( x = df.tsne$X1, y = df.tsne$X2,
           z= df.tsne$X3,
           point.col = color[points],
           surface  = FALSE)

#고차원 데이터의 차원 축소와 시각화 방법
#https://skyeong.net/186


#머신러닝 - 분류
#         - 회귀
#         - 군집분류


#API_ Application Programing Interface
#대부분 시간데이터를 가진것이 api사용_계속적으로 업데이트를 할수없기때문
#google map _ https://cloud.google.com/maps-platform/#get-started
#위에서 API KEY 받기 



##공간시각화

#Google map 사용 
#
#절차
#1.R최신버전 설치
#2.ggplot2최신버전 설치
#3.ggmap 설치
#4.구글맵을 사용하기 위한 API Key 획득
#5.구글맵을 이용한 공간 시간화 수행

intall.packages("ggmap")
library(ggmap)
register_google(key = "AIzaSyBW1-gQiLvNeJ3_pTZnF_rhU3sxbIPHC9c")

#geocode : 특정 지점의 경도(lon)/위도(lat)를 알려주는 함수 
#tibble 형식으로 나옴 _ data.frame과 비슷 _ 직접 사용 x
gc <- geocode(enc2utf8("제주"))  #enc문자를 utf8로 encoding
gc

#경도/위도를 숫자로 변환 必
cen <- as.numeric(gc) 
cen

##지도표시 
map <- get_googlemap(center = cen) #지도 중심형 좌표 
ggmap(map)          #경도 위도를 알경우 c(경도, 위도)


gc <- geocode(enc2utf8("한라산"))
cen <- as.numeric((gc))
map <- get_googlemap(center = cen,        #지도 중심점 좌표
                     zoom = 10,           #지도 확대 청도
                     size = c(640,640),   #지도크기
                     maptype = "roadmap") #지도유형 _ hybrid 유형 有
ggmap(map)


#R에서는 경도,위도  
#Google 에서는 위도,경도 순서 


cen <- c(126.561099,33.253077)
map <- get_googlemap( center = cen ,
                      zoom =17,
                     maptype = "roadmap")
ggmap(map)

##지도에 marker 표시하기

gc <- geocode(enc2utf8("제주"))
cen <- as.numeric(gc)
map <- get_googlemap(center = cen,
                     maptype = "roadmap",
                     marker = gc)
ggmap(map)


names <- c("용두암", "성산일출봉" ,"정방폭포",
           "중문관광단지","한라산1100고지","차귀도")

addr <- c("제주시 용두암길 15",
          "서귀포시 성산읍 성산리",
          "서귀포시 동흥동 289-3",
          '서귀포시 중문동 2624-1',
          '서귀포시 색달동 산1-2',
          '제주시 한경면 고산리 125')

gc <- geocode( enc2utf8(addr))
gc

##관광지 명칭과  좌표값으로  data frame 생성

df <- data.frame(name = names , lon = gc$lon, lat = gc$lat)
df
   #경도와 위도의 평균값을 지도의 중심값으로 
cen <- c(mean(df$lon),mean(df$lat)) 

map <- get_googlemap(center = cen , 
                     maptype = "roadmap",
                     zoom = 10,
                     size = c(640,640),
                     marker = gc  )  #gc에는 위도 경도 값이 들어가 있음 
ggmap(map)


##지도에 관광지 이름 추가
gmap <-  ggmap(map)
gmap +
    geom_text(data = df,             #데이터 셋
              aes(x = lon, y = lat), #텍스트 위치
              size = 5,              #텍스트 크기
              label =df$name)        # 텍스트 이름 


###바람 데이터를 지도에 표시하기 
##지도에 데이터 표시

dim(wind)

str( wind)

sp <- sample( 1:nrow(wind) , 50)   #50 개 샘플링 
df <- wind[sp,]
head(df)


cen <- c(mean(df$lon),mean(df$lat)) #지도중심점 설정
gc <- data.frame(lon = df$lon, lat = df$lat) 
head(gc)
    
##지도에 marker  표시                      
map <-  get_googlemap(center = cen ,
                      maptype = "roadmap",
                      zoom = 6,
                      marker = gc)
ggmap(map)


##바람 속도를 지도에 원크기로 표시하기 

map <-  get_googlemap(center = cen ,
                      maptype = "roadmap",
                      zoom = 6 )  #marker은 필요없으니 제거


#alpha:투명도 
#size = spd 사이즈는 바람의 spd로 하겠다
#원의크기 조절 ( 1부터 14범위로 원의크기 지정)

gmap <- ggmap(map)
gmap + 
    geom_point ( data = df, 
                 aes( x = lon , y = lat, size = spd), 
                 alpha = 0.4 , col = "blue")+
    scale_size_continuous(range = c(1,25)) 


#단계 구분도 
install.packages("ggiraphExtra")
library(ggiraphExtra)

dim(USArrests)
str(USArrests)
head(USArrests)

library(tibble)

crime <- rownames_to_column(USArrests, var = "state")
crime$state <- tolower(crime$state)
str(crime)

install.packages("mapproj")
library(mapproj)

state_map <- map_data( "state")
str(state_map)
ggChoropleth(data = crime,
             aes(fill = Murder,
                 map_id = state),
             map = state_map)


##한국행정지도를 이용하여 단계구분도
##http://rpubs.com/cardiomoon/222145

install.packages("devtools")
devtools::install_github("cardiomoon/kormaps2014")  #devtool은  git hub 에 접근하기 위한 함수 
devtools::install_github("cardiomoon/moonBook2")  #한국 지도가 git hub에 올려져있음 
library(kormaps2014)
library(moonBook)
areacode


library(ggplot2)
theme_set(theme_gray(base_family="NanumGothic"))

ggplot(korpop2,aes(map_id=code,fill=총인구_명))+
    geom_map(map=kormap2,colour="black",size=0.1)+
    expand_limits(x=kormap2$long,y=kormap2$lat)+
    scale_fill_gradientn(colours=c('white','orange','red'))+
    ggtitle("2015년도 시도별 인구분포도")+
    coord_map()

#20191211 11회차
# day 11hw 복습하기
#aggregate 함수 

#============================================================

##data mining : 의사결정을 위해서 DB(정형화 data)로부터 규칙과 
#              패턴을 발견하는 기법

##text mining : Text Data(자연어_비정형data)로부터 규칙과 패턴을 발견하는 기법 
#              자료 처리 과정과 자료분석과정
#대표적 text mining 시각화 도구: word cloud _ 단어 빈도수

#문제정의를 하는 과정에서 텍스트 마이닝 사용 _ 결과를 통해 분석 방향을 정할 수 있다 

##한글 워드클라우드 절차
#1.Java 실행환경 구축_ jdk 설치 절차와 동일
#2.자료수집 (Text자료)
# 2-1 Text file 형태로 수집      cf) 메모장으로 열리면 텍스트 파일
# 2-1 Web scraping을 이용하여 수집   
#3.명사 추출 _JAVA JRE 설치 경로 
Sys.setenv(JAVA_HOME = "C:/Program Files/Java/jre1.8.0_231")
#4.명사 추출
#5.추출된 단어에 대한 빈도수 계산 및 시각화

##필요시 설치_wordcloud 패키지
install.packages("wordcloud")     #word cloud
install.packages("wordcloud2")    #word cloud
install.packages("KoNLP")         #한국어처리
install.packages("RColorBrewer")  #색상선택_단어에 색상부여하기위해

##wordcloud 패키지
library(wordcloud)
library(wordcloud2)
library(KoNLP)
library(RColorBrewer)

##데이터 시각화 도구
library(dplyr)
library(ggplot2)

#R에서 텍스트 파일을 읽을 때 마지막에 공백줄 최소 한줄 _ 없으면 오류

setwd("C:/learnR/자료")
text <- readLines( "mis_document.txt",encoding = "UTF-8") 
text   #읽어들인 파일에서 '명사'를 추출해야함 

#우리말씀 사전 로드
buildDictionary( ext_dic = 'woorimalsam' )
pal2 <- brewer.pal( 8, 'Dark2') #색상팔레트생성
noun <- sapply( text ,extractNoun, USE.NAMES = F) #명사 추출 #extractNoun : 명사 추출
    #sapply는 추출함수 #extractNoun : 명사 추출 
# _USE.NAMES = F_행이름을 안쓰겠다_출력할때 해당 단어가 포함된 줄을 출력 X_ True랑 비교 
str(noun)

#사전에 없는 단어는 추출이 되지않는다 #

##추출된 단어(주로 명사)에 대한 빈도수 계산 및 시각화

noun2 <- unlist(noun) #추출한게 리스트 형식이니 그것을 vector화 
wordcount <- table(noun2)   #명사별 빈도수 카운트 
sort.noun <-  sort( wordcount, decreasing = T )[1:10] # 빈도 내림차순 , 상위 10개 
sort.noun
sort.noun <-  sort.noun[ -1 ] #공백제거 
barplot(sort.noun, names.arg = names(sort.noun),
        col = 'steelblue',main = '빈도수 높은 단어',
         ylab = '단어빈도수')

df <- as.data.frame( sort.noun )
df


ggplot(df, aes( x = df$noun2, y = df$Freq )) +
    geom_bar( stat = "identity", # x축만 있을 때, y축의  default는 빈도수)
             width =0.7,         #Identity 는 y축이 추가되면 y값으로 세로축 으로 표현해준다는 말 
             fill = "steelblue" ) +
    ggtitle('빈도수 높은 단어') +
    theme( plot.title = element_text ( size = 25,
                                      face = "bold",
                                      colour = "steelblue",
                                      hjust = 0, 
                                      vjust = 1 ))+
    labs(x = "명사" , y = '단어빈도수') +
    geom_text( aes ( label = df$Freq ), hjust = -0.3 ) +  #빈도표시 
    coord_flip()


    ## word cloud 작성
    wordcloud( names( wordcount ),   #출력할 단어
               freq = wordcount,     #단어빈도
               scale = c(6, 0.7),     #단어폰트크기(최대,최소 )
               min.freq = 3,          #단어최소빈도
               random.order = F,     #단어출력위치
               rot.per = .1 ,       #90도 회전단어비율
               colors = pal2)         #단어 색
          
    
    
    ##다른 팔레트 사용 
    pal3 <- brewer.pal(9,"Blues") [5:9]
    wordcloud( names( wordcount ),   #출력할 단어
               freq = wordcount,     #단어빈도
               scale = c(6, 0.7),     #단어폰트크기(최대,최소 )
               min.freq = 3,          #단어최소빈도
               random.order = F,     #단어출력위치
               rot.per = .1 ,       #90도 회전단어비율
               colors = pal3)         #단어 색
    
##6.전처리 과정 수행     
# 6-1.불필요한 단어 삭제
# 6-3.생략된 단어를 사전에 등재
    
buildDictionary(ext_dic = "woorimalsam",
                user_dic = data.frame( '정치', 'ncn' ),  
                #(단어 등록,품사) _정치라는 단어가 사전에 해당품사로서 등록하겠다
                
                replace_usr_dic = T )
noun <- sapply( text, extractNoun,USE.NAMES = F )
noun2 <- unlist( noun )

##6-1.불필요한 단어삭제
noun2 <- noun2[ nchar( noun2 ) > 1] #단어길이 2 이상인 거만 취급/ 2 미만은 삭제 
noun2 <- gsub( '하지','',noun2 ) #gsub(a,b,함수 F) _데이터 F에서  a를 b로 바꿔라 _직접지정 
noun2 <- gsub('때문','', noun2 )
wordcount <- table( noun2)


#7. wordcloud


##애국가 형태소 분석

library(KoNLP)
useSystemDic()  #시스템사전 _ 28만 단어
useSejongDic()  #37만단어
useNIADic()     #98만단어 

##애국가 가사:https://www.mois.go.kr/frt/sub/a06/b08/nationalIcon_3/screen.do



##1. 사전 설정   _사용할 사전 설정 
useSejongDic()
##2. 텍스트 데이터 가져오기

word_data <- readLines('애국가(가사).txt')
word_data

##3.명사추출
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F )  
word_data2
#추출된 단어가 '남산위에' => "남산"이라고 안나온 이유는 사전에 없을 수도 
#이처럼 자동화를 넘어 사람의 개입을 통해 정확성을 높여줘야함 _결과 확인 필수 

##3-1.제대로 추출되지않은 단어를 사용자 사전에 등록 

add_words <- c('백두산','남산','철갑','가을','하늘','달')
buildDictionary(user_dic = data.frame(add_words, rep('ncn',length(add_words))), replace_usr_dic = T)
get_dictionary('user_dic')

##3-2.단어 추가 후 다시 명사 추출
word_data2 <- sapply(word_data,extractNoun, USE.NAMES = F)
word_data2 

##4.행렬을 벡터로 변환

undata <- unlist(word_data2)
undata

##5. 사용 빈도 확인  table은 빈도계산 함수 
word_table <- table(undata)
word_table

##6.필터링 : 두글자 이상 단어만 선별 , 공백이나 한 자리 문자를 걸러냄 
#_필터링할 기준을 세우기 

undata2 <- undata[ nchar (undata) >= 2]
undata2
word_table2 <- table(undata2)
word_table2

##7.데이터 정렬
sort( word_table2, decreasing = T)#빈도수 내림차순 정렬 

#애국가 형태 분석 완료
#가장 기본적인 전처리만 수행, 100% 정확한 데이터라 볼 수 없음 

##8.word cloud 작성후 분석

#기본형
wordcloud2( word_table2) 
#배경색 지정
wordcloud2(word_table2,color = "random-light",
           backgroundColor = 'black')

##8-1.모양 변경

wordcloud2(word_table2,
          fontFamily = '맑은고딕',
          size = 1.2 , color = 'random-light',
          backgroundColor = 'black', shape  = 'star')


##8-3. 선택 색상 반복
wordcloud2( word_table2, size =1.6,
            color = rep_len(c('red','blue'),
                            nrow(word_table2)))

wordcloud2( demoFreq, size =1.6,
            color = rep_len(c('red','blue'),
                            nrow(word_table2)))

##8-4.일정방향 정렬
wordcloud2(word_table2,
           minRotation = -pi / 6,
           maxRotation = -pi /6,
           rotateRatio =  1 )


wordcloud2(demoFreq,
           minRotation = -pi / 36,
           maxRotation = -pi /36,
           rotateRatio =  1 )


#모든 웹은 ip를 가지고 있으나 기억하기 어려워서, DMS가 생성 _ eg)naver.com
#서버의 역할은 응답대기
#client의 역할은 서버에게 요청 = request : 1) get   2) post 방식 
#컴퓨터간 통신할 때에는 protocol(약속)이 필요 _ WEB PROTOCOL : HTTP
#HTTP PROTOCOL 은 header & body로 이루어져 있음 
#get 방식은 header에데이터를 담아 전송
#get 방식_ header의 크기는 크지않기 때문에 get방식은 데이터 전송 사이즈  제한이 있다
#get 방식_보안성이 약하다
#주소창 ? 뒤에 보이는 게 get 방식 
#post 방식은 body에 데이터를 담아 전송
#post 방식은 데이터 제한 x 
#post 방식은 보안성이 비교적 좋다 
#html을 해석하는 프로그램이 웹브라우저 
#<HTML>에서는 시작- tag와 끝 tag사이의 내용을 본다 .  첫 태그는 <HTML>
#<HTML>-<HEAD>-</HEAD>-<BODY>-<H1>,</H1>-</BODY>-<HTML>


##scraping _ 주로 body
#WEB SCRAPPING _내가 원하는 자료를 검색 할 수 있어야함 
#<div 공간 분할  / class,id : attribute _ id는 유일 / class 공통 이름 

