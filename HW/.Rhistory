install.packages("RColorBrewer")  #색상선택_단어에 색상부여하기위해
##wordcloud 패키지
library(wordcloud)
library(wordcloud2)
library(KoNLP)
library(RColorBrewer)
##데이터 시각화 도구
library(dplyr)
library(ggplot2)
#R에서 텍스트 파일을 읽을 때 마지막에 공백줄 최소 한줄 _ 없으면 오류
setwd("C:/learnR/자료")
text <- readLines( "mis_document.txt",encoding = "UTF-8")
text   #읽어들인 파일에서 '명사'를 추출해야함
#우리말씀 사전 로드
buildDictionary( ext_dic = 'woorimalsam' )
pal2 <- brewer.pal( 8, 'Dark2') #색상팔레트생성
noun <- sapply( text,extractNoun, USE.NAMES = F ) #명사 추출 #extractNoun : 명사 추출
#extractNoun : 명사 추출 #USE.NAMES = F_행이름을 안쓰겠다
str(noun)
#사전에 없는 단어는 추출이 되지않는다 #
##추출된 단어(주로 명사)에 대한 빈도수 계산 및 시각화
noun2 <- unlist(noun) #추출한게 리스트 형식이니 그것을 vector화
wordcount <- table(noun2)
sort.noun <-  sort( wordcount, decreasing = T )[1:10] # 빈도 내림차순 , 상위 10개
sort.noun
sort.noun <-  sort.noun[ -1 ] #공백제거
barplot(sort.noun, names.arg = names(sort.noun),
col = 'steelblue',main = '빈도수 높은 단어',
ylab = '단어빈도수 ')
df <- as.data.frame( sort.noun )
df
ggplot(df, aes( x= df$noun2, y = df$Freq ))+
geom_bar( stat = "identity",
width =0.7,
fill = "steelblue" )+
ggtitle('빈도수 높은 단어')+
theme( plot.title = element_text (size = 25,
face = "bold",
colour = "steelblue",
hjust = 0,
vjust = 1 ))+
labs(x = "명사" , y = '단어빈도수') +
geom_text( aes ( lable = df$Freq ), hjust = -0.3 ) +  #빈도표시
coord_flip()
## word cloud 작성
wordcloud( names( wordcount ),   #출력할 단어
freq = wordcount,     #단어빈도
scale = c(6, 0.7),     #단어폰트크기(최대,최소 )
min.freq = 3,          #단어최소빈도
random.order = F,     #단어출력위치
rot.per = .1 ,       #90도 회전단어비율
colors = pal2)         #단어 색
##다른 팔레트 사용
pal3 <- brewer.pal(9,"Blues") [5:9]
wordcloud( names( wordcount ),   #출력할 단어
freq = wordcount,     #단어빈도
scale = c(6, 0.7),     #단어폰트크기(최대,최소 )
min.freq = 3,          #단어최소빈도
random.order = F,     #단어출력위치
rot.per = .1 ,       #90도 회전단어비율
colors = pal3)         #단어 색
##6.전처리 과정 수행
# 6-1.불필요한 단어 삭제
# 6-3.생략된 단어를 사전에 등재
buildDictionary(ext_dic = "woorimalsam",
user_dic = data.frame( '정치', 'ncn' ),  #(단어 등록,품사) _정치라는 단어가 사전에 해당품사로서 등록하겠다
replace_usr_dic = T )
noun <- sapply( text, extractNoun,USE.NAMES = F )
noun2 <- unlist( noun )
##6-1.불필요한 단어삭제
noun2 <- noun2[ nchar( noun2 ) > 1] #단어길이 2 이상인 거만 취급/ 2 미만은 삭제
noun2 <- gsub( '하지','',noun2 ) #gsub(a,b,) _ a를 b로 바꿔라 _직접지정
noun2 <- gsub('때문','', noun2 )
wordcount <- table( noun2)
#7. wordcloud
install.packages("wordcloud")
install.packages("wordcloud2")
install.packages("KoNLP")
install.packages("RColorBrewer")
install.packages("wordcloud2")
install.packages("KoNLP")
install.packages("RColorBrewer")
install.packages("RColorBrewer")
df <- as.data.frame( sort.noun )
df
buildDictionary( ext_dic = 'woorimalsam' )
pal2 <- brewer.pal( 8, 'Dark2') #색상팔레트생성
noun <- sapply( text ,extractNoun, USE.NAMES = F )
#extractNoun : 명사 추출 #USE.NAMES = F_행이름을 안쓰겠다
str(noun)
noun2 <- unlist(noun) #추출한게 리스트 형식이니 그것을 vector화
wordcount <- table(noun2)
sort.noun <-  sort( wordcount, decreasing = T )[1:10] # 빈도 내림차순 , 상위 10개
sort.noun
sort.noun <-  sort.noun[ -1 ] #공백제거
barplot(sort.noun, names.arg = names(sort.noun),
col = 'steelblue',main = '빈도수 높은 단어',
ylab = '단어빈도수 ')
barplot(sort.noun, names.arg = names(sort.noun),
col = 'steelblue',main = '빈도수 높은 단어',
ylab = '단어빈도수')
df <- as.data.frame( sort.noun )
df
ggplot(df, aes( x = df$noun2, y = df$Freq )) +
geom_bar( stat = "identity",
width =0.7,
fill = "steelblue" ) +
ggtitle('빈도수 높은 단어') +
theme( plot.title = element_text ( size = 25,
face = "bold",
colour = "steelblue",
hjust = 0,
vjust = 1 ))+
labs(x = "명사" , y = '단어빈도수') +
geom_text( aes ( lable = df$Freq ), hjust = -0.3 ) +  #빈도표시
coord_flip()
ggplot(df, aes( x = df$noun2, y = df$Freq )) +
geom_bar( stat = "identity",
width =0.7,
fill = "steelblue" ) +
ggtitle('빈도수 높은 단어') +
theme( plot.title = element_text ( size = 25,
face = "bold",
colour = "steelblue",
hjust = 0,
vjust = 1 ))+
labs(x = "명사" , y = '단어빈도수') +
geom_text( aes ( label = df$Freq ), hjust = -0.3 ) +  #빈도표시
coord_flip()
noun
wordcount <- table(noun2)
wordcount
ggplot(df, aes( x = df$noun2, y = df$Freq )) +
geom_bar( stat = "identity",
width =0.7,
fill = "steelblue" ) +
ggtitle('빈도수 높은 단어') +
theme( plot.title = element_text ( size = 25,
face = "bold",
colour = "steelblue",
hjust = 0,
vjust = 1 ))+
labs(x = "명사" , y = '단어빈도수') +
geom_text( aes ( label = df$Freq ), hjust = -0.3 ) +  #빈도표시
coord_flip()
noun <- sapply( text ,extractNoun, USE.NAMES = F );noun #명사 추출 #extractNoun : 명사 추출
noun <- sapply( text ,extractNoun, USE.NAMES = T );noun #명사 추출 #extractNoun : 명사 추출
df
library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
#1. 사전 설정
useSejongDic()
word_data
word_data <- readLines('애국가(가사).txt')
word_data
word_data2 <- readLines('애국가(가사).txt')
word_data2
word_data <- readLines('애국가(가사).txt')
word_data
#3.명사추출
word_data2 <- sapply(word_data, extractNoun, USE.NAMES = F )
word_data2
get_dictionary('user_dic')
buildDictionary(user_dic = data.frame(add_words, rep('ncn',length(add_words))),
replace_user_dic = T)
get_dictionary('user_dic')
#3-2.단어 추가 후 다시 명사 추출
word_data2 <- sapply(word_data,extractNoun, USE.NAMES = F)
word_data2
add_words <- c('백두산','남산','철갑','가을','하늘','달')
buildDictionary(user_dic = data.frame(add_words, rep('ncn',length(add_words))),
replace_user_dic = T)
buildDictionary(user_dic = data.frame(add_words, rep('ncn',length(add_words))), replace_usr_dic = T)
get_dictionary('user_dic')
#3-2.단어 추가 후 다시 명사 추출
word_data2 <- sapply(word_data,extractNoun, USE.NAMES = F)
word_data2
undata
undata <- unlist(word-data2)
undata
undata <- unlist(word_data2)
undata
#5. 사용 빈도 확인
word-table <- table(undata)
#5. 사용 빈도 확인
word_table <- table(undata)
word_table
undata2 <- undata[ nchar (undata >= 2]
word_table2
word_table2 <- table(undata2)
word_table2
undata2 <- undata[ nchar (undata) >= 2]
undata2
word_table2 <- table(undata2)
word_table2
#7.데이터 정렬
sort( word_table2, decreasing = T)
word_table2 <- table(undata2)
word_table2
#7.데이터 정렬
sort( word_table2, decreasing = T)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2( word_table2)
wordcloud2(word_table2,color = "random-light",
backgroundColor = 'black')
#배경색 지정
wordcloud2(word_table2,color = "random-light",
backgroundColor = 'black')
wordcloud(word_table2,
fontFamily = '맑은고딕',
size = 1.2 , color = 'random-light',
backgroundColor = 'black', shape  = 'star')
wordcloud(word_table2,
fontFamily = '맑은고딕',
size = 1.2 , color = 'random-light',
backgroundColor = 'black', shape  = 'star')
##8-3. 선택 색상 반복
wordCloud2( word_table2, size =1.6,
color = rep_len(c('red','blue'),
nrow(word-table2)))
wordcloud2(word_table2,
fontFamily = '맑은고딕',
size = 1.2 , color = 'random-light',
backgroundColor = 'black', shape  = 'star')
wordCloud2( word_table2, size =1.6,
color = rep_len(c('red','blue'),
nrow(word-table2)))
##8-3. 선택 색상 반복
wordcloud2( word_table2, size =1.6,
color = rep_len(c('red','blue'),
nrow(word-table2)))
##8-3. 선택 색상 반복
wordcloud2( word_table2, size =1.6,
color = rep_len(c('red','blue'),
nrow(word_table2)))
wordcloud2( demoFreq, size =1.6,
color = rep_len(c('red','blue'),
nrow(word_table2)))
##8-4.일정방향 정렬
wordcloud2(word_table2,
minRotation = -pi / 6,
maxRotation = -pi /6,
rotateRatio =  1 )
wordcloud2(demoFreq,
minRotation = -pi / 6,
maxRotation = -pi /6,
rotateRatio =  1 )
##8-4.일정방향 정렬
wordcloud2(word_table2,
minRotation = -pi / 12,
maxRotation = -pi /12,
rotateRatio =  1 )
##8-4.일정방향 정렬
wordcloud2(word_table2,
minRotation = -pi / 36,
maxRotation = -pi /36,
rotateRatio =  1 )
##8-4.일정방향 정렬
wordcloud2(word_table2,
minRotation = -pi / 6,
maxRotation = -pi /6,
rotateRatio =  1 )
wordcloud2(demoFreq,
minRotation = -pi / 6,
maxRotation = -pi /6,
rotateRatio =  1 )
wordcloud2(demoFreq,
minRotation = -pi / 12,
maxRotation = -pi /12,
rotateRatio =  1 )
wordcloud2(demoFreq,
minRotation = -pi / 36,
maxRotation = -pi /36,
rotateRatio =  1 )
## 패키지 불러오기
library(rvest)
library(dplyr)
#
# R 에서 웹문서 가져오기
#
# 웹에 있는 데이터를 가져오는 단계
#     요청: GET과 POST 방식
#     추출 및 저장
# 관련 R 패키지
#   XML, RCurl, httr, rvest, …
#
#
install.packages( "rvest" )
install.packages("rvest")
## 변수 입력하기
QUERY <- "제주" # 검색키워드
DATE  <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 검색시작날짜 & 검색종료날짜
DATE  <- format( DATE, "%Y.%m.%d" )
PAGE  <- 1
## 날짜 리스트 만들기
DATE_START <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 시작일자
DATE_END   <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 종료일자
## 패키지 불러오기
library(rvest)
library(dplyr)
## 변수 입력하기
QUERY <- "제주" # 검색키워드
DATE  <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 검색시작날짜 & 검색종료날짜
DATE  <- format( DATE, "%Y.%m.%d" )
PAGE  <- 1
naver_url_1 <- "https://search.naver.com/search.naver?&where=news&query="
naver_url_2 <- "&pd=3&ds="
naver_url_3 <- "&de="
## 네이버 검색결과 url 리스트에서 관련기사 url 리스트 만들기
news_url <- c()
news_date <-c()
for ( date_i in DATE ){
for ( page_i in PAGE ){
dt <- format( as.Date( date_i, origin = "1970-01-01" ), "%Y.%m.%d" )
naver_url <- paste0( naver_url_1, QUERY, naver_url_2, dt, naver_url_3, dt, naver_url_4, page_i )
html <- read_html( naver_url )
temp <- unique( html_nodes( html, '#main_pack' ) %>%     # id= 는 # 을 붙인다
html_nodes( css = '.news ' ) %>%         # class= 는 css= 를 붙인다
html_nodes( css = '.type01' ) %>%
html_nodes( 'a' )%>%
html_attr( 'href' ) )
news_url <- c( news_url, temp )
news_date <- c( news_date, rep( dt, length( temp ) ) )
}
print( dt ) # 진행상황을 알기 위함이니 속도가 느려지면 제외
}
## 패키지 불러오기
library(rvest)
library(dplyr)
## 변수 입력하기
QUERY <- "제주" # 검색키워드
DATE  <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 검색시작날짜 & 검색종료날짜
DATE  <- format( DATE, "%Y.%m.%d" )
PAGE  <- 1
naver_url_1 <- "https://search.naver.com/search.naver?&where=news&query="
naver_url_2 <- "&pd=3&ds="
naver_url_3 <- "&de="
naver_url_4 <- "&start="
## 날짜 리스트 만들기
DATE_START <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 시작일자
DATE_END   <- as.Date( as.character( 20191211 ), format = "%Y%m%d" ) # 종료일자
DATE <- DATE_START:DATE_END
DATE <- as.Date( DATE, origin = "1970-01-01" )
## 게시물 번호 리스트 만들기
PAGE <- seq( from = 1, to = 41, by = 10 ) # 시작값과 종료값을 지정해줄 수 있습니다.
PAGE <- seq( from = 1, by = 10, length.out = 5) # 시작값과 원하는 갯수를 지정할 수도 있습니다.
## 네이버 검색결과 url 리스트에서 관련기사 url 리스트 만들기
news_url <- c()
news_date <-c()
for ( date_i in DATE ){
for ( page_i in PAGE ){
dt <- format( as.Date( date_i, origin = "1970-01-01" ), "%Y.%m.%d" )
naver_url <- paste0( naver_url_1, QUERY, naver_url_2, dt, naver_url_3, dt, naver_url_4, page_i )
html <- read_html( naver_url )
temp <- unique( html_nodes( html, '#main_pack' ) %>%     # id= 는 # 을 붙인다
html_nodes( css = '.news ' ) %>%         # class= 는 css= 를 붙인다
html_nodes( css = '.type01' ) %>%
html_nodes( 'a' )%>%
html_attr( 'href' ) )
news_url <- c( news_url, temp )
news_date <- c( news_date, rep( dt, length( temp ) ) )
}
print( dt ) # 진행상황을 알기 위함이니 속도가 느려지면 제외
}
NEWS0 <- as.data.frame( cbind( date = news_date, url = news_url, query = QUERY))
NEWS1 <- NEWS0[ which( grepl( "news.naver.com", NEWS0$url ) ), ]         # 네이버뉴스(news.naver.com)만 대상으로 한다
NEWS1 <- NEWS1[ which( !grepl( "sports.news.naver.com", NEWS1$url ) ), ] # 스포츠뉴스(sports.news.naver.com)는 제외한다
NEWS2 <- NEWS1[ !duplicated( NEWS1 ), ] # 중복된 링크 제거
## 뉴스 페이지에 있는 기사의 제목과 본문을 크롤링
NEWS2$news_title   <- ""
NEWS2$news_content <- ""
for ( i in 1:dim( NEWS2 )[ 1 ] ){
html <- read_html( as.character( NEWS2$url[ i ] ) )
temp_news_title   <- repair_encoding( html_text( html_nodes( html, '#articleTitle' ) ), from = 'utf-8' )
temp_news_content <- repair_encoding( html_text( html_nodes( html, '#articleBodyContents') ), from = 'utf-8' )
if ( length( temp_news_title ) > 0 ) {
NEWS2$news_title[ i ]   <- temp_news_title
NEWS2$news_content[i] <- temp_news_content
}
}
NEWS2$news_content <- gsub( "// flash 오류를 우회하기 위한 함수 추가\nfunction _flash_removeCallback()", "", NEWS2$news_content )
NEWS <- NEWS2 # 최종 결과 저장
NEWS
NEWS$news_content
# 워드클라우드
library( KoNLP )
useSejongDic()
word_data <- sapply( NEWS$news_content, extractNoun, USE.NAMES = F )
word_data
undata <- unlist( word_data )
undata
word_table <- table( undata )
word_table
undata2 <- undata[ nchar( undata ) >= 2 ]
undata2
word_table2 <- table( undata2 )
word_table2
sort( word_table2, decreasing = T )
library( wordcloud2 )
wordcloud2( word_table2, minRotation = -pi / 6, maxRotation = -pi / 6, rotateRatio = 1 )
library(wordcloud)
library(wordcloud2)
library(KoNLP)
library(RColorBrewer)
##wordcloud 패키지
library(wordcloud)
library(wordcloud2)
library(KoNLP)
library(RColorBrewer)
##데이터 시각화 도구
library(dplyr)
library(ggplot2)
#문1)
#20대 국회 개원 여·야 3당 대표 국회연설문에 대해 각각 워드클라우드를
#작성하시오.
#예제소스 파일은 ‘ex_10-1.txt’, ‘ex_10-2.txt’, ‘ex_10-3.txt’이다.
setwd("C:/learnR/HW")
text <- readLines( "ex_10-1.txt",encoding = "UTF-8")
text <- readLines( "ex_10-2.txt",encoding = "UTF-8")
text <- readLines( "ex_10-3.txt",encoding = "UTF-8")
text1<- readLines( "ex_10-1.txt",encoding = "UTF-8")
text2<- readLines( "ex_10-2.txt",encoding = "UTF-8")
text3 <- readLines( "ex_10-3.txt",encoding = "UTF-8")
text3<- readLines( "ex_10-3.txt",encoding = "UTF-8")
text1<- readLines( "ex_10-1.txt",encoding = "UTF-8") ; text1
text2<- readLines( "ex_10-2.txt",encoding = "UTF-8") ; text2
text3<- readLines( "ex_10-3.txt",encoding = "UTF-8") ; text3
buildDictionary(ext = 'woorimalsam')
pal <- brewer.pal(8 , 'Dark2')
pal
n.1 <- sapplly(text.1,extractNoun,USE.NAMES = F)
n.1 <- sapply(text.1,extractNoun,USE.NAMES = F)
n.1 <- sapply(text1,extractNoun,USE.NAMES = F)
n.1 <- sapply(text1,extractNoun,USE.NAMES = F);n.1
noun.1 <- sapply(text1,extractNoun,USE.NAMES = F);noun.1
n1 <- unlist(noun.1)
n1 <- unlist(noun.1) ; n1
cnt.1 <- table(n1) ; cnt.1
sort.noun <- sort(cnt.1,decreasing = T )
sort.noun <- sort(cnt.1,decreasing = T ); sort.noun
sort.1 <- sort(cnt.1,decreasing = T ); sort.1
df.1 <- as.data.frame(sort.1)
df.1 <- as.data.frame(sort.1) ; df.1
ggplot
sort.1
n1 <- unlist(noun.1) ; n1
cnt.1 <- table(n1) ; cnt.1
cnt.1 <- table(n1) ; cnt.1
sort.1 <- sort(cnt.1,decreasing = T ); sort.1
n1
cnt.1
edit.1 <- n1[nchar(n1) > 1]
edit.1 <- n1[nchar(n1) > 1];edit.1
cnt.1 <- table ( edit.1)
cnt.1 <- table ( edit.1) ; cnt.1
wordcloud(names(cnt.1),
freq =cnt.1,
scale = c( 6,0.5),
min.freq = 3,
random.order = F,
rot.per = .1 ,
colors = pal)
wordcloud(names(cnt.1),
freq =cnt.1,
scale = c( 6,0.5),
min.freq = 2,
random.order = F,
rot.per = .1 ,
colors = pal)
wordcloud(names(cnt.1),
freq =cnt.1,
scale = c( 6,0.5),
min.freq = 2,
random.order = T,
rot.per = .1 ,
colors = pal)
wordcloud(names(cnt.1),
freq =cnt.1,
scale = c( 6,0.5),
min.freq = 3,
random.order = T,
rot.per = .1 ,
colors = pal)
wordcloud(names(cnt.1),
freq =cnt.1,
scale = c( 6,0.5),
min.freq = 3,
random.order = T,
rot.per = .1 ,
colors = pal, shape = rect)
wordcloud(names(cnt.1),
freq =cnt.1,
scale = c( 6,0.5),
min.freq = 3,
random.order = T,
rot.per = .1 ,
colors = pal)
